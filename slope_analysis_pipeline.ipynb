{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT = C:\\Gis_Projects\\slope_analysis_delivery\n",
      "Note:\n",
      "Please ensure that PROJECT_ROOT is set to the absolute path of your actual \"slope_analysis_delivery\" project directory.\n",
      "For example:\n",
      "PROJECT_ROOT = r\"C:\\GIS_Projects\\slope_analysis_delivery\"\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import arcpy\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Project root directory\n",
    "# ------------------------------------------------------------------\n",
    "# PROJECT_ROOT should be set to the absolute path of the project root\n",
    "# directory (i.e. the folder that contains this notebook and the\n",
    "# data/, output/, and workspace/ subdirectories).\n",
    "#\n",
    "# Please make sure this path is correct for your local environment.\n",
    "#\n",
    "# Example:\n",
    "# If the \"slope_analysis_delivery\" folder is located directly under\n",
    "# the C: drive, then PROJECT_ROOT should be:\n",
    "# r\"C:\\slope_analysis_delivery\"\n",
    "#\n",
    "PROJECT_ROOT = r\"C:\\Gis_Projects\\slope_analysis_delivery\"\n",
    "\n",
    "# Print the value of PROJECT_ROOT\n",
    "print(\"PROJECT_ROOT =\", PROJECT_ROOT)\n",
    "print(\n",
    "    \"Note:\\n\"\n",
    "    \"Please ensure that PROJECT_ROOT is set to the absolute path of your actual \"\n",
    "    \"\\\"slope_analysis_delivery\\\" project directory.\\n\"\n",
    "    \"For example:\\n\"\n",
    "    \"PROJECT_ROOT = r\\\"C:\\\\GIS_Projects\\\\slope_analysis_delivery\\\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================\n",
    "# Project configuration\n",
    "# ==================================================================\n",
    "# This section defines all project-level configuration variables,\n",
    "# including input datasets, workspace locations, output paths, and\n",
    "# analysis parameters used throughout the slope analysis pipeline.\n",
    "# ==================================================================\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Input dataset paths\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# 1.1. DEM raster path (LiDAR-derived, 1 m resolution)\n",
    "DEM = os.path.join(PROJECT_ROOT, r\"data\\input\\dem\\dem_1m_hamilton.tif\")\n",
    "\n",
    "# 1.2. Hamilton Primary Parcels dataset path (already clipped to the Hamilton City boundary)\n",
    "PARCELS_GDB = os.path.join(PROJECT_ROOT, r\"data\\input\\parcels\\parcels.gdb\")\n",
    "PARCELS_RAW_FC = os.path.join(PARCELS_GDB, \"hamilton_primary_parcels\")\n",
    "\n",
    "# 1.3. Constraint dataset paths (areas excluded from developable land analysis\n",
    "CONSTRAINTS_GDB = os.path.join(PROJECT_ROOT, r\"data\\input\\constraints\\constraints.gdb\")\n",
    "SNA_FC = os.path.join(CONSTRAINTS_GDB, \"Hamilton_Significant_Natural_Area\")\n",
    "OPEN_SPACE_FC = os.path.join(CONSTRAINTS_GDB, \"Hamilton_Open_Space_Zone\")\n",
    "KNOWLEDGE_FC = os.path.join(CONSTRAINTS_GDB, \"Hamilton_Knowledge_Zone\")\n",
    "FACILITIES_FC = os.path.join(CONSTRAINTS_GDB, \"Hamilton_Facilities_Zone\")\n",
    "\n",
    "# 1.4. The residential and non-residential dataset path\n",
    "ZONING_GDB = os.path.join(PROJECT_ROOT, r\"data\\input\\zoning\\zoning.gdb\")\n",
    "RES_NONRES_ZONE_FC = os.path.join(ZONING_GDB, \"hamilton_residential_and_nonResidential_zone\")\n",
    "RES_NONRES_ZONE_FIELD = \"Zone\"  \n",
    "\n",
    "# 1.5. Hamilton City boundary dataset path\n",
    "BOUNDARY_GDB = os.path.join(PROJECT_ROOT, r\"data\\input\\boundary\\boundary.gdb\")\n",
    "BOUNDARY_HAMILTON_FC = os.path.join(BOUNDARY_GDB, \"boundary_hamilton\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Workspace dataset paths (intermediate analysis outputs)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "WORKSPACE_GDB = os.path.join(PROJECT_ROOT, r\"data\\workspace\\ws.gdb\")\n",
    "CONSTRAINTS_MERGED_FC = os.path.join(WORKSPACE_GDB, \"constraints_merged\")\n",
    "CONSTRAINTS_DISSOLVED_FC = os.path.join(WORKSPACE_GDB, \"constraints_dissolved\")\n",
    "PARCELS_ERASED_FC = os.path.join(WORKSPACE_GDB, \"parcels_erased_constraints\")\n",
    "PARCELS_ZONED_FC = os.path.join(WORKSPACE_GDB, \"parcels_zoned\")\n",
    "PARCEL_ID_FIELD = \"id\"\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. Output dataset paths (final analysis results and deliverables)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "SLOPE_GDB = os.path.join(PROJECT_ROOT, r\"data\\output\\slope.gdb\")\n",
    "# The path of parcels_slope dataset, which contains all calculated values and also remain all original values\n",
    "PARCELS_SLOPE = os.path.join(SLOPE_GDB, \"parcels_slope\")\n",
    "# The final deliverable feature class for parcel-level slope analysis\n",
    "PARCELS_SLOPE_DELIVER = os.path.join(SLOPE_GDB, \"parcels_slope_deliver\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. Slope classification thresholds (degrees)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "SLOPE_CLASS = [\n",
    "    (0, 6, \"SLOPE_0_6\"),\n",
    "    (6, 12, \"SLOPE_6_12\"),\n",
    "    (12, 18, \"SLOPE_12_18\"),\n",
    "    (18, 25, \"SLOPE_18_25\"),\n",
    "    (25, 35, \"SLOPE_25_35\"),\n",
    "    (35, 90, \"SLOPE_35_90\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Preflight Validation Report (inputs must exist; workspace/output may be created) ===\n",
      "\n",
      "All required folders and datasets are present. Ready to run the pipeline.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================\n",
    "# Preflight project structure validation\n",
    "# ==================================================================\n",
    "# This module performs a fail-fast validation of the project structure\n",
    "# and required input datasets before running the slope analysis pipeline.\n",
    "#\n",
    "# Purpose\n",
    "# -------\n",
    "# - Ensure all required input datasets exist and are accessible.\n",
    "# - Verify that the expected project folder structure is present.\n",
    "# - Automatically create missing workspace and output containers\n",
    "#   (directories and empty File Geodatabases), if enabled.\n",
    "#\n",
    "# Important notes\n",
    "# ---------------\n",
    "# - Input datasets are NEVER created or modified by this module.\n",
    "# - Only workspace and output containers may be created.\n",
    "# - This validation is intended to be run once at the start of the\n",
    "#   notebook, before any GIS processing is executed.\n",
    "# ==================================================================\n",
    "\n",
    "\n",
    "def ensure_gdb(path):\n",
    "    \"\"\"\n",
    "    Ensure a File Geodatabase (.gdb) exists at the given path.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Absolute path to the target File Geodatabase, e.g.\n",
    "        r\"C:\\\\GIS_Projects\\\\slope_analysis_delivery\\\\data\\\\workspace\\\\ws.gdb\".\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - This function creates the .gdb container only (not feature classes/tables).\n",
    "    - The geodatabase will be created in the parent directory if it does not exist.\n",
    "    \"\"\"\n",
    "\n",
    "    folder, name = os.path.split(path)\n",
    "\n",
    "    if not arcpy.Exists(path):\n",
    "        print(f\"The GDB file does not exist, now creating a new GDB file: {path}\")\n",
    "        arcpy.CreateFileGDB_management(folder, name)\n",
    "\n",
    "\n",
    "def _exists_dataset(path: str) -> bool:\n",
    "    \"\"\"\n",
    "    Return True if an ArcGIS dataset exists.\n",
    "\n",
    "    This helper wraps arcpy.Exists() to safely check existence of:\n",
    "    - File Geodatabases (.gdb)\n",
    "    - Feature classes / tables inside a geodatabase\n",
    "    - Raster datasets\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Use os.path.isdir / os.path.isfile for normal filesystem paths.\n",
    "    - arcpy.Exists() is the correct check for ArcGIS datasets in a GDB.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return arcpy.Exists(path)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def validate_project_structure(\n",
    "    exit_on_fail: bool = True, create_missing_outputs: bool = True\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Preflight validation for the slope analysis pipeline.\n",
    "\n",
    "    This function performs a fail-fast validation of the required project\n",
    "    structure and input datasets before running any GIS processing.\n",
    "\n",
    "    Validation rules\n",
    "    ----------------\n",
    "    - Input folders and input datasets MUST already exist. Missing inputs\n",
    "      are always treated as errors.\n",
    "    - Workspace and output containers may be created automatically when\n",
    "      create_missing_outputs=True (e.g., ws.gdb, slope.gdb, csv/, plots/).\n",
    "    - This function NEVER creates or modifies input datasets. It only creates\n",
    "      missing output containers (directories and empty .gdb files).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    exit_on_fail : bool\n",
    "        If True, stop execution immediately when validation errors are detected.\n",
    "    create_missing_outputs : bool\n",
    "        If True, create missing workspace/output containers. Inputs are never created.\n",
    "    \"\"\"\n",
    "\n",
    "    errors = []\n",
    "    warnings = []\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # A) Required folder structure (filesystem directories)\n",
    "    # ------------------------------------------------------------------\n",
    "    data_dir = os.path.join(PROJECT_ROOT, \"data\")\n",
    "    input_dir = os.path.join(PROJECT_ROOT, r\"data\\input\")\n",
    "    workspace_dir = os.path.join(PROJECT_ROOT, r\"data\\workspace\")\n",
    "    output_dir = os.path.join(PROJECT_ROOT, r\"data\\output\")\n",
    "\n",
    "    required_dirs = [\n",
    "        (\"data\", data_dir),\n",
    "        (\"data/input\", input_dir),\n",
    "        (\"data/workspace\", workspace_dir),\n",
    "        (\"data/output\", output_dir),\n",
    "    ]\n",
    "\n",
    "    for label, d in required_dirs:\n",
    "        if not os.path.isdir(d):\n",
    "            errors.append(f\"[MISSING DIR] {label}: {d}\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # B) Required input datasets (ArcGIS datasets; must exist)\n",
    "    # ------------------------------------------------------------------\n",
    "    required_inputs = [\n",
    "        (\"DEM raster\", DEM),\n",
    "        (\"Parcels GDB\", PARCELS_GDB),\n",
    "        (\"Parcels feature class\", PARCELS_RAW_FC),\n",
    "        (\"Constraints GDB\", CONSTRAINTS_GDB),\n",
    "        (\"SNA feature class\", SNA_FC),\n",
    "        (\"Open Space feature class\", OPEN_SPACE_FC),\n",
    "        (\"Knowledge feature class\", KNOWLEDGE_FC),\n",
    "        (\"Facilities feature class\", FACILITIES_FC),\n",
    "        (\"Zoning GDB\", ZONING_GDB),\n",
    "        (\"Res/Non-res zone feature class\", RES_NONRES_ZONE_FC),\n",
    "        (\"Boundary GDB\", BOUNDARY_GDB),\n",
    "        (\"Hamilton boundary feature class\", BOUNDARY_HAMILTON_FC),\n",
    "    ]\n",
    "\n",
    "    for label, p in required_inputs:\n",
    "        if not _exists_dataset(p):\n",
    "            errors.append(f\"[MISSING INPUT] {label}: {p}\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # C) Output containers (deliverables and derived products)\n",
    "    # ------------------------------------------------------------------\n",
    "    csv_dir = os.path.join(PROJECT_ROOT, r\"data\\output\\csv\")\n",
    "    plots_dir = os.path.join(PROJECT_ROOT, r\"data\\output\\plots\")\n",
    "\n",
    "    output_dirs = [\n",
    "        (\"data/output/csv\", csv_dir),\n",
    "        (\"data/output/plots\", plots_dir),\n",
    "    ]\n",
    "\n",
    "    for label, d in output_dirs:\n",
    "        if not os.path.isdir(d):\n",
    "            if create_missing_outputs:\n",
    "                os.makedirs(d, exist_ok=True)\n",
    "                warnings.append(f\"[CREATED DIR] {label}: {d}\")\n",
    "            else:\n",
    "                errors.append(f\"[MISSING DIR] {label}: {d}\")\n",
    "\n",
    "    # Output GDB (final outputs)\n",
    "    if not _exists_dataset(SLOPE_GDB):\n",
    "        if create_missing_outputs:\n",
    "            try:\n",
    "                ensure_gdb(SLOPE_GDB)\n",
    "                warnings.append(f\"[CREATED GDB] slope.gdb: {SLOPE_GDB}\")\n",
    "            except Exception as e:\n",
    "                errors.append(f\"[FAILED CREATE] slope.gdb: {SLOPE_GDB} | {e}\")\n",
    "        else:\n",
    "            errors.append(f\"[MISSING OUTPUT] slope.gdb: {SLOPE_GDB}\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # D) Workspace container (intermediate datasets; can be regenerated)\n",
    "    # ------------------------------------------------------------------\n",
    "    if not _exists_dataset(WORKSPACE_GDB):\n",
    "        if create_missing_outputs:\n",
    "            try:\n",
    "                ensure_gdb(WORKSPACE_GDB)\n",
    "                warnings.append(f\"[CREATED GDB] ws.gdb: {WORKSPACE_GDB}\")\n",
    "            except Exception as e:\n",
    "                errors.append(f\"[FAILED CREATE] ws.gdb: {WORKSPACE_GDB} | {e}\")\n",
    "        else:\n",
    "            errors.append(f\"[MISSING WORKSPACE] ws.gdb: {WORKSPACE_GDB}\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # E) Report + exit behaviour\n",
    "    # ------------------------------------------------------------------\n",
    "    print(\n",
    "        \"\\n=== Preflight Validation Report \"\n",
    "        \"(inputs must exist; workspace/output may be created) ===\"\n",
    "    )\n",
    "\n",
    "    if warnings:\n",
    "        print(\"\\nWarnings / Actions:\")\n",
    "        for w in warnings:\n",
    "            print(\" -\", w)\n",
    "\n",
    "    if errors:\n",
    "        print(\"\\nErrors:\")\n",
    "        for e in errors:\n",
    "            print(\" -\", e)\n",
    "\n",
    "        msg = f\"\\nPreflight validation failed: {len(errors)} issue(s) found.\"\n",
    "        if exit_on_fail:\n",
    "            raise SystemExit(msg)\n",
    "        else:\n",
    "            print(msg)\n",
    "    else:\n",
    "        print(\n",
    "            \"\\nAll required folders and datasets are present. Ready to run the pipeline.\\n\"\n",
    "        )\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Entry point: run preflight validation before executing the pipeline\n",
    "# ------------------------------------------------------------------\n",
    "validate_project_structure(exit_on_fail=True, create_missing_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boundary extent/mask: C:\\Gis_Projects\\slope_analysis_delivery\\data\\input\\boundary\\boundary.gdb\\boundary_hamilton\n",
      "Workspace: C:\\Gis_Projects\\slope_analysis_delivery\\data\\workspace\\ws.gdb\n",
      "Spatial Reference: NZGD_2000_Transverse_Mercator\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================\n",
    "# ArcPy environment configuration\n",
    "# ==================================================================\n",
    "# Configure geoprocessing environment settings used by the slope\n",
    "# analysis pipeline (workspace, spatial reference, raster alignment,\n",
    "# extent, and mask).\n",
    "# ==================================================================\n",
    "\n",
    "\n",
    "def set_env() -> None:\n",
    "    \"\"\"\n",
    "    Initialise ArcPy environment settings for the slope analysis pipeline.\n",
    "\n",
    "    This function should be called once at the start of the workflow,\n",
    "    before running any raster or spatial analysis tools.\n",
    "\n",
    "    It configures:\n",
    "    - workspace and overwrite behaviour\n",
    "    - Spatial Analyst license checkout\n",
    "    - output coordinate system (from DEM)\n",
    "    - snapRaster and cellSize (aligned to DEM)\n",
    "    - extent and mask (prefer Hamilton boundary; fallback to DEM extent)\n",
    "    \"\"\"\n",
    "    # Core geoprocessing behaviour\n",
    "    arcpy.env.overwriteOutput = True\n",
    "    arcpy.env.workspace = WORKSPACE_GDB\n",
    "\n",
    "    # Required extension for Spatial Analyst tools (e.g., Slope, Reclassify, TabulateArea)\n",
    "    arcpy.CheckOutExtension(\"Spatial\")\n",
    "\n",
    "    # Read DEM properties (spatial reference, extent, etc.)\n",
    "    dem_desc = arcpy.Describe(DEM)\n",
    "\n",
    "    # Ensure outputs align to DEM (reproducible raster processing)\n",
    "    arcpy.env.outputCoordinateSystem = dem_desc.spatialReference\n",
    "    arcpy.env.snapRaster = DEM\n",
    "    arcpy.env.cellSize = DEM\n",
    "\n",
    "    # Constrain processing extent/mask to Hamilton boundary when available;\n",
    "    # otherwise fallback to the DEM extent.\n",
    "    if arcpy.Exists(BOUNDARY_HAMILTON_FC):\n",
    "        arcpy.env.extent = BOUNDARY_HAMILTON_FC\n",
    "        arcpy.env.mask = BOUNDARY_HAMILTON_FC\n",
    "        print(f\"Boundary extent/mask: {BOUNDARY_HAMILTON_FC}\")\n",
    "    else:\n",
    "        arcpy.env.extent = dem_desc.extent\n",
    "        # Mask is intentionally not set when boundary is missing\n",
    "        print(\"Boundary feature not found; using DEM extent only.\")\n",
    "\n",
    "    print(f\"Workspace: {arcpy.env.workspace}\")\n",
    "    print(f\"Spatial Reference: {dem_desc.spatialReference.name}\")\n",
    "\n",
    "\n",
    "# Entry point: initialise ArcPy env once before running the pipeline\n",
    "set_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Spatial Join (parcel centroid within zoning polygon)...\n",
      "Created parcels-with-zone FC: C:\\Gis_Projects\\slope_analysis_delivery\\data\\workspace\\ws.gdb\\parcels_zoned\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Spatial join: attach zoning information to parcels\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def run_spatial_join_zone_to_parcels(overwrite: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Attach zoning information to parcels using a spatial join.\n",
    "\n",
    "    This step assigns a zoning category (Residential / Non-Residential)\n",
    "    to each parcel by performing a Spatial Join where the parcel centroid\n",
    "    falls within a zoning polygon (match_option=\"HAVE_THEIR_CENTER_IN\").\n",
    "\n",
    "    Only parcels with a valid zoning assignment are retained.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    PARCELS_ZONED_FC\n",
    "        Parcel feature class with an added zoning field, stored in\n",
    "        WORKSPACE_GDB.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    overwrite : bool, optional\n",
    "        If True, delete and recreate the output feature class if it\n",
    "        already exists. Default is False.\n",
    "    \"\"\"\n",
    "\n",
    "    ensure_gdb(WORKSPACE_GDB)\n",
    "\n",
    "    if overwrite and arcpy.Exists(PARCELS_ZONED_FC):\n",
    "        print(f\"Deleting existing output: {PARCELS_ZONED_FC}\")\n",
    "        arcpy.management.Delete(PARCELS_ZONED_FC)\n",
    "\n",
    "    if arcpy.Exists(PARCELS_ZONED_FC) and not overwrite:\n",
    "        print(f\"Output exists, skip (overwrite=False): {PARCELS_ZONED_FC}\")\n",
    "        return\n",
    "\n",
    "    if not arcpy.Exists(PARCELS_RAW_FC):\n",
    "        raise FileNotFoundError(f\"Target parcels not found: {PARCELS_RAW_FC}\")\n",
    "    if not arcpy.Exists(RES_NONRES_ZONE_FC):\n",
    "        raise FileNotFoundError(f\"Zoning FC not found: {RES_NONRES_ZONE_FC}\")\n",
    "\n",
    "    # FieldMappings: preserve all parcel attributes and append zoning field\n",
    "    fms = arcpy.FieldMappings()\n",
    "    fms.addTable(PARCELS_RAW_FC)\n",
    "\n",
    "    zone_fm = arcpy.FieldMap()\n",
    "    zone_fm.addInputField(RES_NONRES_ZONE_FC, RES_NONRES_ZONE_FIELD)\n",
    "\n",
    "    out_field = zone_fm.outputField\n",
    "    out_field.name = RES_NONRES_ZONE_FIELD\n",
    "    out_field.aliasName = RES_NONRES_ZONE_FIELD\n",
    "    zone_fm.outputField = out_field\n",
    "\n",
    "    zone_fm.mergeRule = \"First\"\n",
    "    fms.addFieldMap(zone_fm)\n",
    "\n",
    "    print(\"Running Spatial Join (parcel centroid within zoning polygon)...\")\n",
    "    arcpy.analysis.SpatialJoin(\n",
    "        target_features=PARCELS_RAW_FC,\n",
    "        join_features=RES_NONRES_ZONE_FC,\n",
    "        out_feature_class=PARCELS_ZONED_FC,\n",
    "        join_operation=\"JOIN_ONE_TO_ONE\",\n",
    "        join_type=\"KEEP_COMMON\",  # Retain only parcels with a valid zoning assignment\n",
    "        field_mapping=fms,\n",
    "        match_option=\"HAVE_THEIR_CENTER_IN\",\n",
    "    )\n",
    "\n",
    "    # Post-join validation: ensure required fields exist for downstream steps\n",
    "    out_fields = {f.name for f in arcpy.ListFields(PARCELS_ZONED_FC)}\n",
    "    if RES_NONRES_ZONE_FIELD not in out_fields:\n",
    "        raise RuntimeError(f\"Zone field not found in output: {RES_NONRES_ZONE_FIELD}\")\n",
    "    if PARCEL_ID_FIELD not in out_fields:\n",
    "        raise RuntimeError(\n",
    "            f\"Parcel id field missing in output ({PARCEL_ID_FIELD}). \"\n",
    "            \"Downstream zonal/join expects it.\"\n",
    "        )\n",
    "\n",
    "    print(f\"Created parcels-with-zone FC: {PARCELS_ZONED_FC}\")\n",
    "\n",
    "\n",
    "# Entry point: attach zoning information to parcels\n",
    "run_spatial_join_zone_to_parcels(overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging 4 constraint feature classes...\n",
      "Created: C:\\Gis_Projects\\slope_analysis_delivery\\data\\workspace\\ws.gdb\\constraints_merged\n",
      "Dissolving merged constraints...\n",
      "Created: C:\\Gis_Projects\\slope_analysis_delivery\\data\\workspace\\ws.gdb\\constraints_dissolved\n",
      "Erasing parcels by dissolved constraints (parcels minus constraints)...\n",
      "Created: C:\\Gis_Projects\\slope_analysis_delivery\\data\\workspace\\ws.gdb\\parcels_erased_constraints\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Preprocess parcels by planning constraints (merge, dissolve, erase)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def preprocess_parcels_by_constraints(overwrite: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Remove non-developable areas from parcels based on planning constraints.\n",
    "\n",
    "    This step preprocesses the zoned parcel dataset by:\n",
    "    1) Merging multiple planning constraint layers into a single feature class\n",
    "    2) Dissolving the merged constraints to remove internal boundaries\n",
    "    3) Erasing constrained areas from parcels (parcels minus constraints)\n",
    "\n",
    "    The result represents parcels with constrained land removed, suitable\n",
    "    for subsequent slope and feasibility analysis.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    PARCELS_ERASED_FC\n",
    "        Parcel feature class with all constraint areas removed, stored in\n",
    "        WORKSPACE_GDB.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    overwrite : bool, optional\n",
    "        If True, existing intermediate outputs will be deleted and recreated.\n",
    "        Default is False.\n",
    "    \"\"\"\n",
    "\n",
    "    ensure_gdb(WORKSPACE_GDB)\n",
    "\n",
    "    _delete_if_exists(CONSTRAINTS_MERGED_FC, overwrite)\n",
    "    _delete_if_exists(CONSTRAINTS_DISSOLVED_FC, overwrite)\n",
    "    _delete_if_exists(PARCELS_ERASED_FC, overwrite)\n",
    "\n",
    "    # Skip processing when all intermediate outputs already exist\n",
    "    # and overwrite is disabled\n",
    "    if (\n",
    "        arcpy.Exists(CONSTRAINTS_MERGED_FC)\n",
    "        and arcpy.Exists(CONSTRAINTS_DISSOLVED_FC)\n",
    "        and arcpy.Exists(PARCELS_ERASED_FC)\n",
    "        and not overwrite\n",
    "    ):\n",
    "        print(\"Preprocess outputs already exist, skip (overwrite=False).\")\n",
    "        return\n",
    "\n",
    "    # Validate required input constraint layers and parcel dataset\n",
    "    inputs = [SNA_FC, OPEN_SPACE_FC, KNOWLEDGE_FC, FACILITIES_FC]\n",
    "    _require_exists(inputs)\n",
    "    if not arcpy.Exists(PARCELS_ZONED_FC):\n",
    "        raise FileNotFoundError(f\"Raw parcels not found: {PARCELS_ZONED_FC}\")\n",
    "\n",
    "    # 1) Merge constraints\n",
    "    print(\"Merging 4 constraint feature classes...\")\n",
    "    arcpy.management.Merge(inputs=inputs, output=CONSTRAINTS_MERGED_FC)\n",
    "    print(f\"Created: {CONSTRAINTS_MERGED_FC}\")\n",
    "\n",
    "    # 2) Dissolve constraints\n",
    "    print(\"Dissolving merged constraints...\")\n",
    "    arcpy.management.Dissolve(\n",
    "        in_features=CONSTRAINTS_MERGED_FC,\n",
    "        out_feature_class=CONSTRAINTS_DISSOLVED_FC,\n",
    "        dissolve_field=None,\n",
    "        multi_part=\"MULTI_PART\",\n",
    "    )\n",
    "    print(f\"Created: {CONSTRAINTS_DISSOLVED_FC}\")\n",
    "\n",
    "    # 3) Erase parcels by constraints\n",
    "    print(\"Erasing parcels by dissolved constraints (parcels minus constraints)...\")\n",
    "    arcpy.analysis.Erase(\n",
    "        in_features=PARCELS_ZONED_FC,\n",
    "        erase_features=CONSTRAINTS_DISSOLVED_FC,\n",
    "        out_feature_class=PARCELS_ERASED_FC,\n",
    "    )\n",
    "    print(f\"Created: {PARCELS_ERASED_FC}\")\n",
    "\n",
    "\n",
    "def _delete_if_exists(path: str, overwrite: bool) -> None:\n",
    "    \"\"\"\n",
    "    Delete an existing ArcGIS dataset when overwrite is enabled.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path to the dataset to delete.\n",
    "    overwrite : bool\n",
    "        If True, the dataset will be deleted when it exists.\n",
    "    \"\"\"\n",
    "\n",
    "    if overwrite and arcpy.Exists(path):\n",
    "        print(f\"Deleting existing output: {path}\")\n",
    "        arcpy.management.Delete(path)\n",
    "\n",
    "\n",
    "def _require_exists(paths: list[str]) -> None:\n",
    "    \"\"\"\n",
    "    Ensure that all required ArcGIS datasets exist.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    paths : list of str\n",
    "        Paths to required datasets.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    FileNotFoundError\n",
    "        If any required dataset is missing.\n",
    "    \"\"\"\n",
    "\n",
    "    missing = [p for p in paths if not arcpy.Exists(p)]\n",
    "    if missing:\n",
    "        raise FileNotFoundError(f\"Missing required input datasets: {missing}\")\n",
    "\n",
    "\n",
    "# Entry point: preprocess parcels by removing constrained areas\n",
    "preprocess_parcels_by_constraints(overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating slope raster using Slope tool...\n",
      "Slope raster saved: C:\\Gis_Projects\\slope_analysis_delivery\\data\\workspace\\ws.gdb\\slope_degree\n",
      "Running ZonalStatisticsAsTable (ALL)...\n",
      "Zonal table saved: C:\\Gis_Projects\\slope_analysis_delivery\\data\\workspace\\ws.gdb\\zonal_all\n",
      "Copying parcels to output FC: C:\\Gis_Projects\\slope_analysis_delivery\\data\\output\\slope.gdb\\parcels_slope\n",
      "Joining fields ['MEAN', 'MAX'] into C:\\Gis_Projects\\slope_analysis_delivery\\data\\output\\slope.gdb\\parcels_slope...\n",
      "Created parcels slope FC: C:\\Gis_Projects\\slope_analysis_delivery\\data\\output\\slope.gdb\\parcels_slope\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Slope calculation and parcel-level zonal statistics\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def run_slope_and_zonal(overwrite=False):\n",
    "    \"\"\"\n",
    "    Calculate slope from the DEM and derive parcel-level slope statistics.\n",
    "\n",
    "    This step computes a slope raster (in degrees) from the input DEM and\n",
    "    calculates parcel-level zonal statistics (MEAN and MAX) using parcels\n",
    "    with constraint areas already removed.\n",
    "\n",
    "    The resulting slope metrics are joined back to a parcel feature class\n",
    "    for subsequent analysis and delivery.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    overwrite : bool, optional\n",
    "        If True, force recalculation of intermediate outputs (e.g., slope raster\n",
    "        and zonal statistics table). Default is False.\n",
    "\n",
    "        - overwrite=False:\n",
    "            Reuse existing intermediate outputs when available. This speeds up\n",
    "            repeated runs and avoids unnecessary recalculation.\n",
    "\n",
    "        - overwrite=True:\n",
    "            Force a full recalculation. Recommended when:\n",
    "                * the DEM has changed\n",
    "                * slope calculation parameters have changed\n",
    "                * previous results are suspected to be incorrect\n",
    "                * a full workflow refresh is required\n",
    "\n",
    "    Workflow\n",
    "    --------\n",
    "    1. Compute slope raster from DEM (degrees)\n",
    "    2. Calculate parcel-level zonal statistics (MEAN, MAX)\n",
    "    3. Create output parcel feature class\n",
    "    4. Join slope statistics to parcels\n",
    "\n",
    "    Outputs\n",
    "    -------\n",
    "    slope raster\n",
    "        Stored in WORKSPACE_GDB as an intermediate product.\n",
    "    zonal statistics table\n",
    "        Stored in WORKSPACE_GDB.\n",
    "    PARCELS_SLOPE\n",
    "        Parcel feature class with MEAN and MAX slope values, stored in SLOPE_GDB.\n",
    "    \"\"\"\n",
    "\n",
    "    ensure_gdb(WORKSPACE_GDB)\n",
    "    ensure_gdb(SLOPE_GDB)\n",
    "\n",
    "    slope_raster = os.path.join(WORKSPACE_GDB, \"slope_degree\")\n",
    "    stats_table = os.path.join(WORKSPACE_GDB, \"zonal_all\")\n",
    "\n",
    "    # Step 1: DEM → Slope (use the Slope tool)\n",
    "    if overwrite or not arcpy.Exists(slope_raster):\n",
    "        print(\"Calculating slope raster using Slope tool...\")\n",
    "\n",
    "        out_slope = arcpy.sa.Slope(\n",
    "            in_raster=DEM,\n",
    "            output_measurement=\"DEGREE\",\n",
    "            z_factor=1,  # vertical exaggeration factor (units already in meters)\n",
    "            method=\"PLANAR\",\n",
    "        )\n",
    "        out_slope.save(slope_raster)\n",
    "        print(f\"Slope raster saved: {slope_raster}\")\n",
    "    else:\n",
    "        print(f\"Using existing slope raster: {slope_raster}\")\n",
    "\n",
    "    # Step 2: Calculate parcel-level zonal statistics (MEAN, MAX)\n",
    "    print(\"Running ZonalStatisticsAsTable (ALL)...\")\n",
    "    arcpy.sa.ZonalStatisticsAsTable(\n",
    "        in_zone_data=PARCELS_ERASED_FC,\n",
    "        zone_field=PARCEL_ID_FIELD,\n",
    "        in_value_raster=slope_raster,\n",
    "        out_table=stats_table,\n",
    "        ignore_nodata=\"DATA\",  # ignore nodata\n",
    "        statistics_type=\"ALL\",\n",
    "    )\n",
    "    print(f\"Zonal table saved: {stats_table}\")\n",
    "\n",
    "    # Step 3: Create output parcel feature class for slope results\n",
    "    print(f\"Copying parcels to output FC: {PARCELS_SLOPE}\")\n",
    "    arcpy.management.CopyFeatures(PARCELS_ERASED_FC, PARCELS_SLOPE)\n",
    "\n",
    "    # Step 4: Join slope statistics (MEAN, MAX) to parcels\n",
    "    fields_to_join = [\"MEAN\", \"MAX\"]\n",
    "    print(f\"Joining fields {fields_to_join} into {PARCELS_SLOPE}...\")\n",
    "    arcpy.management.JoinField(\n",
    "        in_data=PARCELS_SLOPE,\n",
    "        in_field=PARCEL_ID_FIELD,\n",
    "        join_table=stats_table,\n",
    "        join_field=PARCEL_ID_FIELD,\n",
    "        fields=fields_to_join,\n",
    "    )\n",
    "\n",
    "    print(f\"Created parcels slope FC: {PARCELS_SLOPE}\")\n",
    "\n",
    "\n",
    "# Entry point: run slope and zonal statistics step\n",
    "run_slope_and_zonal(overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reclassifying slope raster into slope classes...\n",
      "Running TabulateArea (parcel x slope class)...\n",
      "Slope class area table created: C:\\Gis_Projects\\slope_analysis_delivery\\data\\workspace\\ws.gdb\\parcel_slope_class_area\n",
      "Joining slope class area fields back to parcels...\n",
      "Slope class area calculation for each parcel finished.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Parcel-level slope class area calculation (TabulateArea workflow)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def calc_slope_class_area_by_parcel(overwrite: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Calculate parcel-level area (m²) for each slope class.\n",
    "\n",
    "    This step derives parcel-level slope composition by reclassifying a\n",
    "    continuous slope raster (degrees) into discrete slope classes and\n",
    "    computing the area of each class within individual parcels using\n",
    "    the TabulateArea operation.\n",
    "\n",
    "    The resulting slope-class area statistics are permanently joined to\n",
    "    the parcel feature class as AREA_SLOPE_* fields, enabling subsequent\n",
    "    parcel-, zone-, and city-level analysis of slope constraints.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    overwrite : bool, optional\n",
    "        If False (default), existing slope-class area tables and joined\n",
    "        parcel fields are reused when available.\n",
    "        If True, existing slope-class area tables and previously joined\n",
    "        AREA_SLOPE_* fields are removed and fully rebuilt to reflect the\n",
    "        current slope classification settings.\n",
    "\n",
    "    Workflow\n",
    "    --------\n",
    "    1. Reclassify the continuous slope raster (degrees) into discrete\n",
    "       integer-based slope classes defined in SLOPE_CLASS\n",
    "    2. Use TabulateArea to compute the area (m²) of each slope class\n",
    "       within individual parcels\n",
    "    3. Join the resulting area fields back to the parcel feature class\n",
    "    4. Rename fields to semantic AREA_SLOPE_* names\n",
    "\n",
    "    Outputs\n",
    "    -------\n",
    "    parcel slope-class area fields\n",
    "        AREA_SLOPE_* fields added to PARCELS_SLOPE and stored in SLOPE_GDB.\n",
    "    \"\"\"\n",
    "\n",
    "    # Path to continuous slope raster (degrees)\n",
    "    slope_raster = os.path.join(WORKSPACE_GDB, \"slope_degree\")\n",
    "\n",
    "    # Output table storing parcel × slope-class area results\n",
    "    area_table = os.path.join(WORKSPACE_GDB, \"parcel_slope_class_area\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Pre-checks\n",
    "    # ------------------------------------------------------------------\n",
    "    # Ensure parcel feature class exists before running any analysis\n",
    "    if not arcpy.Exists(PARCELS_SLOPE):\n",
    "        print(f\"{PARCELS_SLOPE} not found, skip slope area calculation.\")\n",
    "        return\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Step 1 and 2: Reclassify slope raster and run TabulateArea\n",
    "    # ------------------------------------------------------------------\n",
    "    # If area table already exists and overwrite is False, reuse it\n",
    "    if arcpy.Exists(area_table) and not overwrite:\n",
    "        print(\"Using existing slope class area table.\")\n",
    "    else:\n",
    "\n",
    "        print(\"Reclassifying slope raster into slope classes...\")\n",
    "\n",
    "        # Build RemapRange from SLOPE_CLASS\n",
    "        # Each slope interval is mapped to a sequential integer code:\n",
    "        #   1 = SLOPE_0_6, 2 = SLOPE_6_12, 3 = SLOPE_12_18,\n",
    "        #   4 = SLOPE_18_25, 5 = SLOPE_25_35, 6 = SLOPE_35_90\n",
    "        remap_ranges = []\n",
    "        for lo, hi, _ in SLOPE_CLASS:\n",
    "            remap_ranges.append([lo, hi, len(remap_ranges) + 1])\n",
    "        remap = arcpy.sa.RemapRange(remap_ranges)\n",
    "\n",
    "        # Reclassify continuous slope raster to discrete class raster\n",
    "        # Any slope values outside defined ranges are set to NoData\n",
    "        slope_class_raster = arcpy.sa.Reclassify(\n",
    "            slope_raster,\n",
    "            \"Value\",\n",
    "            remap,\n",
    "            \"NODATA\",\n",
    "        )\n",
    "\n",
    "        # Persist the reclassified slope raster for verification and cartographic purposes.\n",
    "        # This raster is saved to allow visual inspection of slope class boundaries\n",
    "        # and to support subsequent map production; it is not used in any further analysis.\n",
    "        out_raster = os.path.join(WORKSPACE_GDB, \"slope_class_raster_all_bins\")\n",
    "        slope_class_raster.save(out_raster)\n",
    "\n",
    "        # Compute area (m²) of each slope class within each parcel\n",
    "        print(\"Running TabulateArea (parcel x slope class)...\")\n",
    "        arcpy.sa.TabulateArea(\n",
    "            in_zone_data=PARCELS_SLOPE,\n",
    "            zone_field=PARCEL_ID_FIELD,\n",
    "            in_class_data=slope_class_raster,\n",
    "            class_field=\"Value\",\n",
    "            out_table=area_table,\n",
    "        )\n",
    "\n",
    "        print(f\"Slope class area table created: {area_table}\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Step 3: Join slope-class area fields back to parcel feature class\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    # Collect VALUE_* fields generated by TabulateArea that should be joined\n",
    "    print(\"Joining slope class area fields back to parcels...\")\n",
    "    join_fields = []\n",
    "    for idx, (_, _, label) in enumerate(SLOPE_CLASS, start=1):\n",
    "        src = f\"VALUE_{idx}\"  # field name in area_table\n",
    "        dst = f\"AREA_{label}\"  # intended final field name in parcels\n",
    "\n",
    "        if src in [f.name for f in arcpy.ListFields(area_table)]:\n",
    "            join_fields.append(src)\n",
    "\n",
    "    # Identify existing joined fields in parcels\n",
    "    # This includes both raw VALUE_* fields and renamed AREA_SLOPE_* fields\n",
    "    existing_fields = [f.name for f in arcpy.ListFields(PARCELS_SLOPE)]\n",
    "    to_delete = [\n",
    "        f\n",
    "        for f in existing_fields\n",
    "        if f.startswith(\"VALUE_\") or f.startswith(\"AREA_SLOPE_\")\n",
    "    ]\n",
    "\n",
    "    # If overwrite=True, remove previously joined fields to ensure a clean rebuild\n",
    "    if overwrite and to_delete:\n",
    "        print(f\"Deleting existing joined fields: {len(to_delete)} fields\")\n",
    "        arcpy.management.DeleteField(PARCELS_SLOPE, to_delete)\n",
    "\n",
    "    # Permanently join slope-class area fields to parcel feature class\n",
    "    arcpy.management.JoinField(\n",
    "        in_data=PARCELS_SLOPE,\n",
    "        in_field=PARCEL_ID_FIELD,\n",
    "        join_table=area_table,\n",
    "        join_field=PARCEL_ID_FIELD,\n",
    "        fields=join_fields,\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Step 4: Rename VALUE_* fields to semantic AREA_SLOPE_* field names\n",
    "    # ------------------------------------------------------------------\n",
    "    existing_fields = {f.name for f in arcpy.ListFields(PARCELS_SLOPE)}\n",
    "\n",
    "    for idx, (_, _, label) in enumerate(SLOPE_CLASS, start=1):\n",
    "        old = f\"VALUE_{idx}\"  # default field name from TabulateArea\n",
    "        new = f\"AREA_{label}\"  # descriptive, analysis-ready field name\n",
    "\n",
    "        # Skip if VALUE_* field does not exist (already renamed or missing)\n",
    "        if old not in existing_fields:\n",
    "            continue\n",
    "\n",
    "        # Skip renaming if target field name already exists\n",
    "        if new in existing_fields:\n",
    "            print(f\"Field already exists, skip rename: {old} -> {new}\")\n",
    "            continue\n",
    "\n",
    "        # Rename field and update alias\n",
    "        arcpy.management.AlterField(\n",
    "            PARCELS_SLOPE,\n",
    "            old,\n",
    "            new,\n",
    "            new,\n",
    "        )\n",
    "\n",
    "        # Update cached field name set to reflect the rename\n",
    "        existing_fields.remove(old)\n",
    "        existing_fields.add(new)\n",
    "\n",
    "    print(\"Slope class area calculation for each parcel finished.\")\n",
    "\n",
    "\n",
    "# Entry point: calculate parcel-level slope class areas\n",
    "calc_slope_class_area_by_parcel(overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reclassifying slope raster to steep bins (>=18 degrees)...\n",
      "Saved steep raster: C:\\Gis_Projects\\slope_analysis_delivery\\data\\workspace\\ws.gdb\\city_level_steep_slope_classified_raster\n",
      "Converting steep raster to polygons (RasterToPolygon)...\n",
      "Created steep slope polygons: C:\\Gis_Projects\\slope_analysis_delivery\\data\\output\\slope.gdb\\city_level_steep_slope_zones\n",
      "Intersecting steep polygons with parcels...\n",
      "Created parcel steep slope zones: C:\\Gis_Projects\\slope_analysis_delivery\\data\\output\\slope.gdb\\parcel_level_steep_slope_zones\n",
      "Steep slope zone export finished.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Export steep slope zones (>=18°) and intersect with parcels\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def export_steep_slope_zones(overwrite: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Generate steep slope polygons (>=18 degrees) and intersect them with parcels.\n",
    "\n",
    "    This step extracts steep slope areas from the slope raster, converts them\n",
    "    into polygon features, and intersects them with parcel boundaries to\n",
    "    identify the location and extent of steep terrain within individual parcels.\n",
    "\n",
    "    The output supports parcel-level analysis of steep slope distribution,\n",
    "    enabling assessment of where and how steep slopes occur within parcels\n",
    "    rather than simply indicating their presence or absence.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    overwrite : bool, optional\n",
    "        If True, existing steep slope outputs are deleted and fully rebuilt.\n",
    "        If False (default), existing outputs are reused when available.\n",
    "\n",
    "    Workflow\n",
    "    --------\n",
    "    1. Reclassify slope raster to retain steep slopes (>=18 degrees)\n",
    "    2. Convert steep slope raster to polygon features\n",
    "    3. Intersect steep slope polygons with parcels\n",
    "    4. Calculate area (m²) for each parcel-level steep slope feature\n",
    "\n",
    "    Outputs\n",
    "    -------\n",
    "    city_level_steep_slope_zones\n",
    "        Polygon features representing contiguous steep slope areas (>=18°),\n",
    "        classified into three steepness categories (18-25, 25-35, 35-90 degrees).\n",
    "    parcel_level_steep_slope_zones\n",
    "        Parcel-split steep slope polygons with slope_class labels and area (m²),\n",
    "        stored in SLOPE_GDB.\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Input raster: continuous slope values (degrees)\n",
    "    # Each cell value represents the local slope angle in degrees\n",
    "    # ------------------------------------------------------------------\n",
    "    slope_raster = os.path.join(WORKSPACE_GDB, \"slope_degree\")\n",
    "\n",
    "    # Ensure parcel layer exists; steep slope zones are only meaningful\n",
    "    # when analysed within parcel boundaries\n",
    "    if not arcpy.Exists(PARCELS_SLOPE):\n",
    "        print(f\"{PARCELS_SLOPE} not found, skip steep slope zone export.\")\n",
    "        return\n",
    "\n",
    "    # Ensure slope raster exists; it must be generated beforehand\n",
    "    if not arcpy.Exists(slope_raster):\n",
    "        raise ValueError(\n",
    "            f\"{slope_raster} not found. Please run run_slope_and_zonal() first.\"\n",
    "        )\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Output paths and overwrite handling\n",
    "    # ------------------------------------------------------------------\n",
    "    # These outputs are reused across runs unless overwrite=True\n",
    "    out_steep_poly = os.path.join(SLOPE_GDB, \"city_level_steep_slope_zones\")\n",
    "    out_parcel_steep = os.path.join(SLOPE_GDB, \"parcel_level_steep_slope_zones\")\n",
    "\n",
    "    # If outputs already exist:\n",
    "    # - overwrite=False → skip processing to avoid unnecessary recomputation\n",
    "    # - overwrite=True  → delete and fully rebuild outputs\n",
    "    for p in (out_steep_poly, out_parcel_steep):\n",
    "        if arcpy.Exists(p):\n",
    "            if overwrite:\n",
    "                print(f\"Deleting existing output: {p}\")\n",
    "                arcpy.management.Delete(p)\n",
    "            else:\n",
    "                print(f\"Output exists (overwrite=False), skip: {p}\")\n",
    "                return\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Step 1: Reclassify slope raster to retain only steep slopes (>=18°)\n",
    "    # ------------------------------------------------------------------\n",
    "    # This step performs two operations simultaneously:\n",
    "    # 1) Thresholding: slope values <18° are excluded (assigned NoData)\n",
    "    # 2) Discrete classification: retained values are mapped to class codes\n",
    "    print(\"Reclassifying slope raster to steep bins (>=18 degrees)...\")\n",
    "\n",
    "    # Build RemapRange dynamically from SLOPE_CLASS,\n",
    "    # but only keep slope intervals >=18°\n",
    "    remap_ranges = []\n",
    "    code = 0\n",
    "    for lo, hi, _ in SLOPE_CLASS:\n",
    "        # Skip non-steep slope classes\n",
    "        if hi <= 18:\n",
    "            continue\n",
    "        code += 1\n",
    "        remap_ranges.append([lo, hi, code])\n",
    "\n",
    "    # Class code mapping:\n",
    "    #   1 = SLOPE_18_25\n",
    "    #   2 = SLOPE_25_35\n",
    "    #   3 = SLOPE_35_90\n",
    "    remap = arcpy.sa.RemapRange(remap_ranges)\n",
    "\n",
    "    # Reclassify the continuous slope raster:\n",
    "    # - Cells <18° → NoData\n",
    "    # - Cells >=18° → integer class codes (1, 2, 3)\n",
    "    steep_raster = arcpy.sa.Reclassify(\n",
    "        in_raster=slope_raster,\n",
    "        reclass_field=\"Value\",\n",
    "        remap=remap,\n",
    "        missing_values=\"NODATA\",  # explicitly mask non-steep slopes\n",
    "    )\n",
    "\n",
    "    # Persist intermediate raster for QA and validation purposes only.\n",
    "    # This raster supports visual inspection and comparison with derived polygons;\n",
    "    # it is not used in downstream analytical steps.\n",
    "    steep_raster_path = os.path.join(\n",
    "        WORKSPACE_GDB, \"city_level_steep_slope_classified_raster\"\n",
    "    )\n",
    "    steep_raster.save(steep_raster_path)\n",
    "    print(f\"Saved steep raster: {steep_raster_path}\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Step 2: Convert steep slope raster to polygon features\n",
    "    # ------------------------------------------------------------------\n",
    "    # Contiguous raster cells with the same class code are converted\n",
    "    # into polygon features representing steep slope zones\n",
    "    print(\"Converting steep raster to polygons (RasterToPolygon)...\")\n",
    "\n",
    "    arcpy.conversion.RasterToPolygon(\n",
    "        in_raster=steep_raster_path,\n",
    "        out_polygon_features=out_steep_poly,\n",
    "        simplify=\"SIMPLIFY\",\n",
    "        raster_field=\"Value\",  # preserve slope class codes (1/2/3)\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Add human-readable slope class labels to polygon output\n",
    "    # ------------------------------------------------------------------\n",
    "    # RasterToPolygon may output either 'gridcode' or 'Value'\n",
    "    value_field = (\n",
    "        \"gridcode\"\n",
    "        if \"gridcode\" in [f.name for f in arcpy.ListFields(out_steep_poly)]\n",
    "        else \"Value\"\n",
    "    )\n",
    "\n",
    "    # Create a text field to store descriptive slope class labels\n",
    "    if \"slope_class\" not in [f.name for f in arcpy.ListFields(out_steep_poly)]:\n",
    "        arcpy.management.AddField(\n",
    "            out_steep_poly, \"slope_class\", \"TEXT\", field_length=32\n",
    "        )\n",
    "\n",
    "    # Map integer class codes to semantic slope class labels\n",
    "    code_to_label = {\n",
    "        1: \"SLOPE_18_25\",\n",
    "        2: \"SLOPE_25_35\",\n",
    "        3: \"SLOPE_35_90\",\n",
    "    }\n",
    "\n",
    "    # Populate slope_class field based on class code\n",
    "    with arcpy.da.UpdateCursor(out_steep_poly, [value_field, \"slope_class\"]) as cursor:\n",
    "        for v, _ in cursor:\n",
    "            cursor.updateRow((v, code_to_label.get(int(v), \"UNKNOWN\")))\n",
    "\n",
    "    print(f\"Created steep slope polygons: {out_steep_poly}\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Step 3: Intersect steep slope polygons with parcels\n",
    "    # ------------------------------------------------------------------\n",
    "    # This operation splits steep slope polygons by parcel boundaries.\n",
    "    # Each resulting feature represents a specific portion of a parcel\n",
    "    # occupied by a particular steep slope class.\n",
    "    print(\"Intersecting steep polygons with parcels...\")\n",
    "\n",
    "    arcpy.analysis.Intersect(\n",
    "        in_features=[PARCELS_SLOPE, out_steep_poly],\n",
    "        out_feature_class=out_parcel_steep,\n",
    "        join_attributes=\"ALL\",  # retain attributes from both inputs\n",
    "        cluster_tolerance=None,\n",
    "        output_type=\"INPUT\",\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Step 4: Calculate area (m²) for each parcel-level steep slope feature\n",
    "    # ------------------------------------------------------------------\n",
    "    # The calculated area supports parcel-level quantification of\n",
    "    # steep slope extent and distribution\n",
    "    if \"area_m2\" not in [f.name for f in arcpy.ListFields(out_parcel_steep)]:\n",
    "        arcpy.management.AddField(out_parcel_steep, \"area_m2\", \"DOUBLE\")\n",
    "\n",
    "    arcpy.management.CalculateGeometryAttributes(\n",
    "        out_parcel_steep,\n",
    "        [[\"area_m2\", \"AREA\"]],\n",
    "        area_unit=\"SQUARE_METERS\",\n",
    "    )\n",
    "\n",
    "    print(f\"Created parcel steep slope zones: {out_parcel_steep}\")\n",
    "    print(\"Steep slope zone export finished.\")\n",
    "\n",
    "\n",
    "# Entry point: export steep slope zones and intersect with parcels\n",
    "export_steep_slope_zones(overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting parcels with slope area >= 18 degrees (by area fields)\n",
      "Selected parcels: 23663\n",
      "Exporting steep parcels to: C:\\Gis_Projects\\slope_analysis_delivery\\data\\output\\slope.gdb\\parcels_affected_by_steep_slopes\n",
      "Steep parcel export finished.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Export parcels affected by steep slopes (parcel-level selection)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def export_steep_parcels(overwrite: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Export parcels that are affected by steep slopes (>=18 degrees).\n",
    "\n",
    "    This step selects and exports whole parcel polygons that contain\n",
    "    any non-zero area in steep slope classes (18-25, 25-35, or 35-90 degrees),\n",
    "    based on previously calculated parcel-level slope area fields.\n",
    "\n",
    "    The output represents parcel-level exposure to steep slopes, rather\n",
    "    than the geometry of steep slope areas themselves.\n",
    "\n",
    "    Selection rule\n",
    "    --------------\n",
    "    A parcel is selected if:\n",
    "        AREA_SLOPE_18_25 > 0\n",
    "        OR AREA_SLOPE_25_35 > 0\n",
    "        OR AREA_SLOPE_35_90 > 0\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    overwrite : bool, optional\n",
    "        If True, existing output will be deleted and rebuilt.\n",
    "        If False (default), existing output will be reused.\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Pre-check: ensure parcel dataset exists\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    if not arcpy.Exists(PARCELS_SLOPE):\n",
    "        print(f\"{PARCELS_SLOPE} not found, skip steep parcel export.\")\n",
    "        return\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Output feature class\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    # This output contains whole parcel polygons affected by steep slopes (>=18°);\n",
    "    # it does not represent steep slope geometries themselves.\n",
    "    out_fc = os.path.join(SLOPE_GDB, \"parcels_affected_by_steep_slopes\")\n",
    "\n",
    "    # Handle overwrite behaviour:\n",
    "    # - overwrite=False → reuse existing output and skip processing\n",
    "    # - overwrite=True  → delete existing output and rebuild\n",
    "    if arcpy.Exists(out_fc) and not overwrite:\n",
    "        print(f\"{out_fc} already exists, skip (overwrite=False).\")\n",
    "        return\n",
    "    if arcpy.Exists(out_fc) and overwrite:\n",
    "        print(f\"Deleting existing output: {out_fc}\")\n",
    "        arcpy.management.Delete(out_fc)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Precondition check: required slope area fields\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    # These AREA_SLOPE_* fields store the parcel-level area (m²) of\n",
    "    # steep slope classes and are generated by calc_slope_class_area_by_parcel().\n",
    "    # Without them, parcel-level steep slope selection is not possible\n",
    "    required_fields = {\"AREA_SLOPE_18_25\", \"AREA_SLOPE_25_35\", \"AREA_SLOPE_35_90\"}\n",
    "    existing_fields = {f.name for f in arcpy.ListFields(PARCELS_SLOPE)}\n",
    "    missing = sorted(required_fields - existing_fields)\n",
    "    if missing:\n",
    "        raise ValueError(\n",
    "            \"Missing required area fields for steep selection. \"\n",
    "            f\"Please run calc_slope_class_area_by_parcel() first. Missing: {missing}\"\n",
    "        )\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Selection logic\n",
    "    # ------------------------------------------------------------------\n",
    "    # A parcel is considered affected by steep slopes if it contains\n",
    "    # any non-zero area in one or more steep slope classes (>=18°).\n",
    "    # This is a parcel-level boolean selection, not a spatial extraction\n",
    "    # of steep slope geometry.\n",
    "    where = \"AREA_SLOPE_18_25 > 0 OR \" \"AREA_SLOPE_25_35 > 0 OR \" \"AREA_SLOPE_35_90 > 0\"\n",
    "\n",
    "    print(\"Selecting parcels with slope area >= 18 degrees (by area fields)\")\n",
    "\n",
    "    # Create a temporary feature layer to apply attribute selection\n",
    "    lyr = \"parcels_slope_lyr\"\n",
    "    arcpy.management.MakeFeatureLayer(PARCELS_SLOPE, lyr)\n",
    "\n",
    "    # Apply attribute-based selection using slope area fields\n",
    "    arcpy.management.SelectLayerByAttribute(lyr, \"NEW_SELECTION\", where)\n",
    "\n",
    "    # Report number of selected parcels for logging / QA\n",
    "    selected_count = int(arcpy.management.GetCount(lyr)[0])\n",
    "    print(f\"Selected parcels: {selected_count}\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Export selected parcels\n",
    "    # ------------------------------------------------------------------\n",
    "    # The exported feature class contains full parcel geometries\n",
    "    # for all parcels affected by steep slopes.\n",
    "    print(f\"Exporting steep parcels to: {out_fc}\")\n",
    "    arcpy.management.CopyFeatures(lyr, out_fc)\n",
    "\n",
    "    # Clean up temporary layer\n",
    "    arcpy.management.Delete(lyr)\n",
    "\n",
    "    print(\"Steep parcel export finished.\")\n",
    "\n",
    "\n",
    "# Entry point: export parcels affected by steep slopes\n",
    "export_steep_parcels(overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================\n",
    "# Parcel-level steep slope summary metrics (attribute-based)\n",
    "# ==================================================================\n",
    "# This module derives parcel-level steep slope summary metrics from\n",
    "# existing AREA_SLOPE_* fields generated by the slope classification\n",
    "# and TabulateArea workflow.\n",
    "#\n",
    "# IMPORTANT:\n",
    "# - This module performs NO spatial analysis.\n",
    "# - All operations are attribute-based calculations on an existing\n",
    "#   feature class.\n",
    "# - Input AREA_SLOPE_* fields must already exist.\n",
    "# ==================================================================\n",
    "\n",
    "\n",
    "SLOPE_BINS = [\n",
    "    \"AREA_SLOPE_0_6\",\n",
    "    \"AREA_SLOPE_6_12\",\n",
    "    \"AREA_SLOPE_12_18\",\n",
    "    \"AREA_SLOPE_18_25\",\n",
    "    \"AREA_SLOPE_25_35\",\n",
    "    \"AREA_SLOPE_35_90\",\n",
    "]\n",
    "\n",
    "# Subset of slope bins considered \"steep slopes\" (>= 18 degrees)\n",
    "STEEP_BINS = [\"AREA_SLOPE_18_25\", \"AREA_SLOPE_25_35\", \"AREA_SLOPE_35_90\"]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Derived output field names\n",
    "# ------------------------------------------------------------------\n",
    "# TOTAL_FIELD:\n",
    "#   Total slope area within each parcel (sum of all AREA_SLOPE_* fields)\n",
    "TOTAL_FIELD = \"TOTAL_SLOPE_AREA_M2\"\n",
    "\n",
    "# STEEP_M2_FIELD:\n",
    "#   Total steep slope area (>=18°) within each parcel (m²)\n",
    "STEEP_M2_FIELD = \"STEEP_AREA_M2\"\n",
    "\n",
    "# STEEP_PCT_FIELD:\n",
    "#   Percentage of steep slope area relative to total slope area (%)\n",
    "STEEP_PCT_FIELD = \"STEEP_AREA_PCT\"\n",
    "\n",
    "# BIN_FIELD:\n",
    "#   Discrete 5% interval classification of STEEP_AREA_PCT\n",
    "BIN_FIELD = \"STEEP_BIN\"\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Utility functions\n",
    "# ------------------------------------------------------------------\n",
    "def _ensure_field(fc: str, name: str, ftype: str, length: int | None = None) -> None:\n",
    "    \"\"\"\n",
    "    Ensure that a field exists on the target feature class.\n",
    "\n",
    "    If the field already exists, no action is taken.\n",
    "    \"\"\"\n",
    "\n",
    "    fields = {f.name for f in arcpy.ListFields(fc)}\n",
    "    if name in fields:\n",
    "        return\n",
    "    if ftype.upper() == \"TEXT\":\n",
    "        arcpy.management.AddField(fc, name, ftype, field_length=length or 50)\n",
    "    else:\n",
    "        arcpy.management.AddField(fc, name, ftype)\n",
    "\n",
    "\n",
    "def _calc_total_area(fc: str) -> None:\n",
    "    \"\"\"\n",
    "    Calculate TOTAL_SLOPE_AREA_M2 as the sum of all slope-class area fields.\n",
    "    Represents the total slope-covered area within each parcel.\n",
    "    \"\"\"\n",
    "\n",
    "    # Treat NULL/None as 0 to avoid null propagation during summation\n",
    "    expression = \" + \".join([f\"(!{c}! or 0)\" for c in SLOPE_BINS])\n",
    "    arcpy.management.CalculateField(fc, TOTAL_FIELD, expression, \"PYTHON3\")\n",
    "\n",
    "\n",
    "def _calc_steep_area(fc: str) -> None:\n",
    "    \"\"\"\n",
    "    Calculate STEEP_AREA_M2 as the sum of slope areas >=18 degrees.\n",
    "    Represents the absolute extent of steep terrain within each parcel.\n",
    "    \"\"\"\n",
    "\n",
    "    # Treat NULL/None as 0 to avoid null propagation during summation\n",
    "    expression = \" + \".join([f\"(!{c}! or 0)\" for c in STEEP_BINS])\n",
    "    arcpy.management.CalculateField(fc, STEEP_M2_FIELD, expression, \"PYTHON3\")\n",
    "\n",
    "\n",
    "def _calc_steep_pct(fc: str) -> None:\n",
    "    \"\"\"\n",
    "    Calculate STEEP_AREA_PCT as the proportion of steep slope area\n",
    "    relative to total slope area within each parcel.\n",
    "    \"\"\"\n",
    "\n",
    "    # Guard against NULL/None and divide-by-zero\n",
    "    expression = (\n",
    "        f\"(100.0 * (!{STEEP_M2_FIELD}! or 0) / (!{TOTAL_FIELD}! or 0)) \"\n",
    "        f\"if (!{TOTAL_FIELD}! or 0) > 0 else 0\"\n",
    "    )\n",
    "    arcpy.management.CalculateField(fc, STEEP_PCT_FIELD, expression, \"PYTHON3\")\n",
    "\n",
    "\n",
    "def _calc_bin(fc: str) -> None:\n",
    "    \"\"\"\n",
    "    Classify STEEP_AREA_PCT into discrete 5% interval bins (e.g. 0-5%, 5-10%, …, 95-100%).\n",
    "\n",
    "    The resulting STEEP_BIN field supports parcel-level grouping,\n",
    "    statistical summaries, and categorical visualisation.\n",
    "    \"\"\"\n",
    "\n",
    "    code_block = \"\"\"\n",
    "def bin_label(pct):\n",
    "    if pct is None:\n",
    "        return None\n",
    "    try:\n",
    "        pct = float(pct)\n",
    "    except:\n",
    "        return None    \n",
    "\n",
    "    # handle 100 explicitly\n",
    "    if pct >= 100:\n",
    "        return \"95-100%\"\n",
    "\n",
    "    edges = list(range(0, 105, 5))  # 0...100\n",
    "    for i in range(len(edges)-1):\n",
    "        lo = edges[i]\n",
    "        hi = edges[i+1]\n",
    "        if lo <= pct < hi:\n",
    "            return f\"{lo}-{hi}%\"\n",
    "    return None\n",
    "\"\"\"\n",
    "\n",
    "    arcpy.management.CalculateField(\n",
    "        fc,\n",
    "        BIN_FIELD,\n",
    "        f\"bin_label(!{STEEP_PCT_FIELD}!)\",\n",
    "        \"PYTHON3\",\n",
    "        code_block,\n",
    "    )\n",
    "\n",
    "\n",
    "def add_steep_bins(fc: str) -> None:\n",
    "    \"\"\"\n",
    "    Derive and populate parcel-level steep slope summary fields.\n",
    "\n",
    "    This function computes parcel-level steep slope metrics from\n",
    "    precomputed AREA_SLOPE_* fields, including:\n",
    "      - total slope area\n",
    "      - total steep slope area (>=18°)\n",
    "      - percentage of steep slope area\n",
    "      - 5% interval steep slope proportion bins\n",
    "\n",
    "    Preconditions\n",
    "    -------------\n",
    "    - The target feature class must already contain AREA_SLOPE_* fields\n",
    "      generated by calc_slope_class_area_by_parcel().\n",
    "    \"\"\"\n",
    "\n",
    "    if not arcpy.Exists(fc):\n",
    "        raise FileNotFoundError(f\"Target FC not found: {fc}\")\n",
    "\n",
    "    # Verify required input fields exist\n",
    "    existing = {f.name for f in arcpy.ListFields(fc)}\n",
    "    missing_bins = [c for c in SLOPE_BINS if c not in existing]\n",
    "    if missing_bins:\n",
    "        raise ValueError(\n",
    "            \"Missing required slope area fields on target FC. \"\n",
    "            f\"Missing: {missing_bins}. Run calc_slope_class_area_by_parcel() first.\"\n",
    "        )\n",
    "\n",
    "    # Ensure derived fields exist\n",
    "    _ensure_field(fc, TOTAL_FIELD, \"DOUBLE\")\n",
    "    _ensure_field(fc, STEEP_M2_FIELD, \"DOUBLE\")\n",
    "    _ensure_field(fc, STEEP_PCT_FIELD, \"DOUBLE\")\n",
    "    _ensure_field(fc, BIN_FIELD, \"TEXT\", length=12)\n",
    "\n",
    "    # Perform attribute calculations\n",
    "    print(\"Calculating TOTAL_SLOPE_AREA_M2...\")\n",
    "    _calc_total_area(fc)\n",
    "\n",
    "    print(\"Calculating STEEP_AREA_M2...\")\n",
    "    _calc_steep_area(fc)\n",
    "\n",
    "    print(\"Calculating STEEP_AREA_PCT...\")\n",
    "    _calc_steep_pct(fc)\n",
    "\n",
    "    print(\"Calculating STEEP_BIN...\")\n",
    "    _calc_bin(fc)\n",
    "\n",
    "    print(\"Steep bin fields added and calculated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating delivery FC: C:\\Gis_Projects\\slope_analysis_delivery\\data\\output\\slope.gdb\\parcels_slope_deliver\n",
      "Deleting 10 fields from delivery FC.\n",
      "Delivery FC created and cleaned.\n",
      "Calculating TOTAL_SLOPE_AREA_M2...\n",
      "Calculating STEEP_AREA_M2...\n",
      "Calculating STEEP_AREA_PCT...\n",
      "Calculating STEEP_BIN...\n",
      "Steep bin fields added and calculated.\n",
      "Exporting delivery parcels_slope to CSV: C:\\Gis_Projects\\slope_analysis_delivery\\data\\output\\csv\\parcels_slope_steep_metrics.csv\n",
      "CSV export finished.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Build delivery-ready parcel slope Feature Class\n",
    "# ------------------------------------------------------------------\n",
    "def build_parcels_slope_delivery_fc(in_fc: str, out_fc: str) -> str:\n",
    "    \"\"\"\n",
    "    Build a delivery-ready parcel slope Feature Class using a whitelist strategy.\n",
    "\n",
    "    This function prepares a clean, analysis-ready Feature Class for downstream\n",
    "    delivery (CSV export, pandas analysis, reporting) by:\n",
    "      - copying the source parcel Feature Class\n",
    "      - retaining only an explicitly approved set of delivery fields\n",
    "      - removing all intermediate and non-essential attributes\n",
    "\n",
    "    The whitelist approach ensures a stable and controlled delivery schema,\n",
    "    independent of internal processing or intermediate fields.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_fc : str\n",
    "        Input parcel Feature Class containing full analysis results.\n",
    "    out_fc : str\n",
    "        Output delivery Feature Class path.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Path to the cleaned, delivery-ready Feature Class.\n",
    "    \"\"\"\n",
    "\n",
    "    # These fields represent:\n",
    "    # - parcel identifiers and zoning context\n",
    "    # - geometric attributes\n",
    "    # - parcel-level slope metrics (area by slope class)\n",
    "    keep_fields = [\n",
    "        \"id\",\n",
    "        \"Zone\",\n",
    "        \"calc_area\",\n",
    "        \"Shape_Length\",\n",
    "        \"Shape_Area\",\n",
    "        \"MEAN\",\n",
    "        \"MAX\",\n",
    "        \"AREA_SLOPE_0_6\",\n",
    "        \"AREA_SLOPE_6_12\",\n",
    "        \"AREA_SLOPE_12_18\",\n",
    "        \"AREA_SLOPE_18_25\",\n",
    "        \"AREA_SLOPE_25_35\",\n",
    "        \"AREA_SLOPE_35_90\",\n",
    "    ]\n",
    "\n",
    "    # Ensure input feature class exists\n",
    "    if not arcpy.Exists(in_fc):\n",
    "        raise FileNotFoundError(f\"Input FC not found: {in_fc}\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Create a fresh delivery FC\n",
    "    # Always rebuild to ensure a clean output\n",
    "    # ------------------------------------------------------------------\n",
    "    if arcpy.Exists(out_fc):\n",
    "        arcpy.management.Delete(out_fc)\n",
    "\n",
    "    print(f\"Creating delivery FC: {out_fc}\")\n",
    "    arcpy.management.CopyFeatures(in_fc, out_fc)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Identify system-managed fields that must never be deleted\n",
    "    # ------------------------------------------------------------------\n",
    "    desc = arcpy.Describe(out_fc)\n",
    "    oid_field = getattr(desc, \"OIDFieldName\", None)\n",
    "    shape_field = getattr(desc, \"shapeFieldName\", None)\n",
    "\n",
    "    system_keep = {f for f in [oid_field, shape_field] if f}\n",
    "\n",
    "    # Final whitelist = user-defined fields + required system fields\n",
    "    keep_set = set(keep_fields) | system_keep\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Field cleanup using whitelist strategy\n",
    "    # ------------------------------------------------------------------\n",
    "    existing = [f.name for f in arcpy.ListFields(out_fc)]\n",
    "\n",
    "    # Warn if expected delivery fields are missing\n",
    "    missing = [f for f in keep_fields if f not in existing]\n",
    "    if missing:\n",
    "        print(f\"WARNING: Missing expected fields in delivery FC: {missing}\")\n",
    "\n",
    "    # Delete all fields not explicitly approved for delivery\n",
    "    to_delete = [f for f in existing if f not in keep_set]\n",
    "    if to_delete:\n",
    "        print(f\"Deleting {len(to_delete)} fields from delivery FC.\")\n",
    "        arcpy.management.DeleteField(out_fc, to_delete)\n",
    "    else:\n",
    "        print(\"No fields to delete; delivery FC already clean.\")\n",
    "\n",
    "    print(\"Delivery FC created and cleaned.\")\n",
    "    return out_fc\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Final delivery: export parcel slope metrics to CSV\n",
    "# ------------------------------------------------------------------\n",
    "def export_parcels_slope_to_csv() -> None:\n",
    "    \"\"\"\n",
    "    Export parcel-level slope and steep-slope metrics to CSV for analysis.\n",
    "\n",
    "    This function represents the final delivery step of the parcel-level\n",
    "    slope analysis workflow. It:\n",
    "      1. Builds a clean, delivery-ready parcel Feature Class\n",
    "      2. Derives steep-slope summary metrics on the delivery dataset\n",
    "      3. Exports the resulting attribute table to CSV\n",
    "\n",
    "    The exported CSV is analysis-ready and intended for:\n",
    "      - pandas-based statistical analysis\n",
    "      - plotting and visualisation\n",
    "      - reporting and appendix tables\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Pre-check: ensure parcel slope dataset exists\n",
    "    # ------------------------------------------------------------------\n",
    "    if not arcpy.Exists(PARCELS_SLOPE):\n",
    "        print(f\"{PARCELS_SLOPE} not found, skip CSV export.\")\n",
    "        return\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Output directory for CSV delivery\n",
    "    # ------------------------------------------------------------------\n",
    "    out_dir = os.path.join(PROJECT_ROOT, r\"data\\output\\csv\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    out_name = \"parcels_slope_steep_metrics.csv\"\n",
    "    out_path = os.path.join(out_dir, out_name)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Step 1: Build delivery-clean Feature Class\n",
    "    # This removes all intermediate and non-essential fields\n",
    "    # ------------------------------------------------------------------\n",
    "    delivery_fc = build_parcels_slope_delivery_fc(PARCELS_SLOPE, PARCELS_SLOPE_DELIVER)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Step 2: Derive steep-slope metrics on the delivery FC\n",
    "    # (TOTAL_SLOPE_AREA_M2, STEEP_AREA_M2, STEEP_AREA_PCT, STEEP_BIN)\n",
    "    # ------------------------------------------------------------------\n",
    "    add_steep_bins(delivery_fc)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Step 3: Export attribute table to CSV for pandas\n",
    "    # ------------------------------------------------------------------\n",
    "    print(f\"Exporting delivery parcels_slope to CSV: {out_path}\")\n",
    "\n",
    "    arcpy.conversion.TableToTable(\n",
    "        in_rows=delivery_fc,\n",
    "        out_path=out_dir,\n",
    "        out_name=out_name,\n",
    "    )\n",
    "\n",
    "    print(\"CSV export finished.\")\n",
    "\n",
    "\n",
    "# Entry point: final CSV delivery of parcel slope metrics\n",
    "export_parcels_slope_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded parcels: (56481, 12)\n",
      "Saved city_slope_stats.csv\n",
      "Saved zone_slope_stats.csv\n",
      "Saved zone_slope_stats_res_vs_nonres.csv\n",
      "Saved parcel_steep_stats.csv\n",
      "Saved parcel_steep_bin_counts_0_100_res_nonres.csv\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================\n",
    "# Parcel-level steep slope analysis (post-processing, attribute-only)\n",
    "# ==================================================================\n",
    "# This script performs attribute-based analysis on parcel-level outputs\n",
    "# exported from the ArcPy slope analysis pipeline (CSV delivery).\n",
    "#\n",
    "# Scope\n",
    "# -----\n",
    "# - Load parcel-level slope metrics from CSV\n",
    "# - Produce city-level, zone-level, and parcel-level summary tables\n",
    "# - Derive steep-slope exposure statistics using predefined slope bins\n",
    "# - Export analysis-ready CSV outputs for reporting and plotting\n",
    "#\n",
    "# Notes\n",
    "# -----\n",
    "# - No spatial operations are performed in this script.\n",
    "# - All calculations are based on tabulated slope-area attributes.\n",
    "# - Designed to be reproducible and runnable as a standalone analysis step.\n",
    "# ==================================================================\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Paths\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Output directory for derived CSV tables produced by this script.\n",
    "CSV_PATH = os.path.join(\n",
    "    PROJECT_ROOT,\n",
    "    r\"data\\output\\csv\\parcels_slope_steep_metrics.csv\",\n",
    ")\n",
    "\n",
    "# Output directory for all derived CSV tables generated by this script.\n",
    "OUT_DIR = os.path.join(PROJECT_ROOT, r\"data\\output\\csv\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Constant fields (analysis schema)\n",
    "# These column names define the expected and stable schema of the delivery CSV.\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Slope-area fields representing discrete slope classes (degrees).\n",
    "# These fields are produced by the ArcPy slope classification + TabulateArea workflow.\n",
    "SLOPE_BINS = [\n",
    "    \"AREA_SLOPE_0_6\",\n",
    "    \"AREA_SLOPE_6_12\",\n",
    "    \"AREA_SLOPE_12_18\",\n",
    "    \"AREA_SLOPE_18_25\",\n",
    "    \"AREA_SLOPE_25_35\",\n",
    "    \"AREA_SLOPE_35_90\",\n",
    "]\n",
    "\n",
    "# Core attribute fields expected in the input CSV\n",
    "ZONE_COL = \"Zone\"  # Residential / Non-Residential classification\n",
    "PARCEL_ID_COL = \"id\"  # Unique parcel identifier\n",
    "\n",
    "# Optional derived fields that may already exist in the CSV.\n",
    "# If present, they will be reused to maintain consistency with ArcPy outputs.\n",
    "OPTIONAL_COLS = [\n",
    "    \"TOTAL_SLOPE_AREA_M2\",\n",
    "    \"STEEP_AREA_M2\",\n",
    "    \"STEEP_AREA_PCT\",\n",
    "    \"STEEP_BIN\",\n",
    "]\n",
    "\n",
    "# Zones explicitly targeted in comparative analysis\n",
    "TARGET_ZONES = [\"Residential Zone\", \"Non Residential Zone\"]\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Utilities\n",
    "# --------------------------------------------------\n",
    "\n",
    "\n",
    "def round_pct(df: pd.DataFrame, cols: list[str], ndigits: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Round percentage columns for presentation only.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Applied at final output stage.\n",
    "    - Rounding may cause totals to deviate slightly from 100%.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].round(ndigits)\n",
    "    return df\n",
    "\n",
    "\n",
    "def normalize_steep_bin_label(val: object) -> str:\n",
    "    \"\"\"\n",
    "    Normalise STEEP_BIN labels into a canonical format (e.g., '10-15%').\n",
    "\n",
    "    This function does not reclassify data; it standardises label formatting\n",
    "    to ensure reliable grouping and aggregation.\n",
    "    \"\"\"\n",
    "\n",
    "    if val is None or (isinstance(val, float) and pd.isna(val)):\n",
    "        return \"\"\n",
    "\n",
    "    s = str(val).strip()\n",
    "    if not s:\n",
    "        return \"\"\n",
    "\n",
    "    # Replace en dash / em dash with hyphen\n",
    "    s = s.replace(\"–\", \"-\").replace(\"—\", \"-\")\n",
    "\n",
    "    # Remove spaces\n",
    "    s = re.sub(r\"\\s+\", \"\", s)\n",
    "\n",
    "    # Ensure it ends with %\n",
    "    if not s.endswith(\"%\"):\n",
    "        s = s + \"%\"\n",
    "\n",
    "    # Canonicalize patterns like \"10to15%\" if any (rare)\n",
    "    s = s.replace(\"to\", \"-\")\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "def expected_bins_0_to_100(step: int = 5) -> list[str]:\n",
    "    \"\"\"\n",
    "    Return the expected steep-bin sequence for reporting (0-100% in fixed steps).\n",
    "\n",
    "    This ensures bins with zero counts are still present in output tables.\n",
    "    \"\"\"\n",
    "\n",
    "    bins = []\n",
    "    for lo in range(0, 100, step):\n",
    "        hi = lo + step\n",
    "        bins.append(f\"{lo}-{hi}%\")\n",
    "    return bins\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Load & clean\n",
    "# --------------------------------------------------\n",
    "\n",
    "\n",
    "def load_parcel_slope_data() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load the delivery CSV and enforce a clean analysis schema.\n",
    "\n",
    "    Responsibilities\n",
    "    ----------------\n",
    "    - Validate presence of required base fields (id, Zone, AREA_SLOPE_*)\n",
    "    - Retain optional derived fields if already present\n",
    "    - Enforce numeric types for slope-area attributes\n",
    "    - Normalise STEEP_BIN labels for consistent aggregation\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - No spatial metrics are recomputed here.\n",
    "    - This mirrors downstream logic while preserving upstream results when available.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "    required_cols = [PARCEL_ID_COL, ZONE_COL] + SLOPE_BINS\n",
    "\n",
    "    missing = [c for c in required_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    # Keep required columns + optional columns if present in the CSV\n",
    "    keep_cols = required_cols + [c for c in OPTIONAL_COLS if c in df.columns]\n",
    "    df = df[keep_cols].copy()\n",
    "\n",
    "    # Keep only parcels with valid Zone (equivalent to KEEP_COMMON in Spatial Join)\n",
    "    df = df[df[ZONE_COL].notna()].copy()\n",
    "\n",
    "    # Ensure numeric area values for slope bins\n",
    "    for c in SLOPE_BINS:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    # Total slope-covered area per parcel (compute only if not already present)\n",
    "    if \"TOTAL_SLOPE_AREA_M2\" not in df.columns:\n",
    "        df[\"TOTAL_SLOPE_AREA_M2\"] = df[SLOPE_BINS].sum(axis=1)\n",
    "    else:\n",
    "        df[\"TOTAL_SLOPE_AREA_M2\"] = pd.to_numeric(\n",
    "            df[\"TOTAL_SLOPE_AREA_M2\"], errors=\"coerce\"\n",
    "        ).fillna(0.0)\n",
    "\n",
    "    # If STEEP_AREA_* exist in CSV, keep them as numeric; otherwise, they will be computed\n",
    "    # only where needed by parcel-level function (to keep behavior consistent).\n",
    "    if \"STEEP_AREA_M2\" in df.columns:\n",
    "        df[\"STEEP_AREA_M2\"] = pd.to_numeric(\n",
    "            df[\"STEEP_AREA_M2\"], errors=\"coerce\"\n",
    "        ).fillna(0.0)\n",
    "    if \"STEEP_AREA_PCT\" in df.columns:\n",
    "        df[\"STEEP_AREA_PCT\"] = pd.to_numeric(\n",
    "            df[\"STEEP_AREA_PCT\"], errors=\"coerce\"\n",
    "        ).fillna(0.0)\n",
    "\n",
    "    # Normalize STEEP_BIN values if present (does not change meaning, only formatting)\n",
    "    if \"STEEP_BIN\" in df.columns:\n",
    "        df[\"STEEP_BIN\"] = df[\"STEEP_BIN\"].apply(normalize_steep_bin_label)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# City-level statistics\n",
    "# --------------------------------------------------\n",
    "\n",
    "\n",
    "def city_level_slope_stats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute city-level slope-area totals and percentages.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame with columns:\n",
    "    - area_m2: total area (m²) per slope class\n",
    "    - area_pct: percentage of total slope-covered area\n",
    "    \"\"\"\n",
    "\n",
    "    area = df[SLOPE_BINS].sum()\n",
    "    pct = area / area.sum() * 100.0\n",
    "\n",
    "    out = pd.DataFrame({\"area_m2\": area, \"area_pct\": pct})\n",
    "    return out.sort_values(\"area_m2\", ascending=False)\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Zone-level statistics\n",
    "# --------------------------------------------------\n",
    "\n",
    "\n",
    "def zone_level_slope_stats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute zone-level slope exposure statistics.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame indexed by Zone, including:\n",
    "    - TOTAL_AREA_M2\n",
    "    - AREA_18PLUS_M2 / PCT_18PLUS\n",
    "    - AREA_25PLUS_M2 / PCT_25PLUS\n",
    "    - AREA_35PLUS_M2 / PCT_35PLUS\n",
    "    \"\"\"\n",
    "\n",
    "    zone_area = df.groupby(ZONE_COL)[SLOPE_BINS].sum()\n",
    "    zone_area[\"TOTAL_AREA_M2\"] = zone_area.sum(axis=1)\n",
    "\n",
    "    zone_area[\"AREA_18PLUS_M2\"] = (\n",
    "        zone_area[\"AREA_SLOPE_18_25\"]\n",
    "        + zone_area[\"AREA_SLOPE_25_35\"]\n",
    "        + zone_area[\"AREA_SLOPE_35_90\"]\n",
    "    )\n",
    "    zone_area[\"AREA_25PLUS_M2\"] = (\n",
    "        zone_area[\"AREA_SLOPE_25_35\"] + zone_area[\"AREA_SLOPE_35_90\"]\n",
    "    )\n",
    "    zone_area[\"AREA_35PLUS_M2\"] = zone_area[\"AREA_SLOPE_35_90\"]\n",
    "\n",
    "    zone_area[\"PCT_18PLUS\"] = (\n",
    "        zone_area[\"AREA_18PLUS_M2\"] / zone_area[\"TOTAL_AREA_M2\"] * 100.0\n",
    "    )\n",
    "    zone_area[\"PCT_25PLUS\"] = (\n",
    "        zone_area[\"AREA_25PLUS_M2\"] / zone_area[\"TOTAL_AREA_M2\"] * 100.0\n",
    "    )\n",
    "    zone_area[\"PCT_35PLUS\"] = (\n",
    "        zone_area[\"AREA_35PLUS_M2\"] / zone_area[\"TOTAL_AREA_M2\"] * 100.0\n",
    "    )\n",
    "\n",
    "    return zone_area.sort_values(\"TOTAL_AREA_M2\", ascending=False)\n",
    "\n",
    "\n",
    "def export_res_vs_nonres(zone_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract a Residential vs Non-Residential comparison table from zone-level stats.\n",
    "\n",
    "    Returns a two-row DataFrame for the target zones with core exposure metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    available = [z for z in TARGET_ZONES if z in zone_df.index]\n",
    "    if len(available) < 2:\n",
    "        raise ValueError(\n",
    "            \"Expected both Residential Zone and Non Residential Zone in zone data.\"\n",
    "        )\n",
    "\n",
    "    cols = [\n",
    "        \"TOTAL_AREA_M2\",\n",
    "        \"AREA_18PLUS_M2\",\n",
    "        \"PCT_18PLUS\",\n",
    "        \"AREA_25PLUS_M2\",\n",
    "        \"PCT_25PLUS\",\n",
    "        \"AREA_35PLUS_M2\",\n",
    "        \"PCT_35PLUS\",\n",
    "    ]\n",
    "    return zone_df.loc[available, cols].copy()\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Parcel-level steep analysis\n",
    "# --------------------------------------------------\n",
    "\n",
    "\n",
    "def parcel_level_steep_stats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute parcel-level steep slope exposure metrics for ranking and filtering.\n",
    "\n",
    "    Behaviour\n",
    "    ---------\n",
    "    - Reuse STEEP_AREA_M2 / STEEP_AREA_PCT if present\n",
    "    - Compute missing derived fields when required\n",
    "    - Return only parcels with STEEP_AREA_M2 > 0\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    if \"STEEP_AREA_M2\" not in df.columns:\n",
    "        df[\"STEEP_AREA_M2\"] = (\n",
    "            df[\"AREA_SLOPE_18_25\"] + df[\"AREA_SLOPE_25_35\"] + df[\"AREA_SLOPE_35_90\"]\n",
    "        )\n",
    "\n",
    "    if \"STEEP_AREA_PCT\" not in df.columns:\n",
    "        df[\"STEEP_AREA_PCT\"] = 0.0\n",
    "        mask = df[\"TOTAL_SLOPE_AREA_M2\"] > 0\n",
    "        df.loc[mask, \"STEEP_AREA_PCT\"] = (\n",
    "            df.loc[mask, \"STEEP_AREA_M2\"] / df.loc[mask, \"TOTAL_SLOPE_AREA_M2\"] * 100.0\n",
    "        )\n",
    "\n",
    "    steep_df = df[df[\"STEEP_AREA_M2\"] > 0].copy()\n",
    "    return steep_df.sort_values(\"STEEP_AREA_M2\", ascending=False)\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# STEEP_BIN distribution counts (10-15% ... 95-100%)\n",
    "# --------------------------------------------------\n",
    "\n",
    "\n",
    "def steep_bin_counts_overall_res_nonres(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute STEEP_BIN distribution counts and percentages (0-100% in 5% bins).\n",
    "\n",
    "    Outputs include distributions for:\n",
    "    - All parcels\n",
    "    - Residential Zone\n",
    "    - Non Residential Zone\n",
    "    \"\"\"\n",
    "\n",
    "    if \"STEEP_BIN\" not in df.columns:\n",
    "        raise ValueError(\n",
    "            \"STEEP_BIN column not found in input CSV. Please ensure it is exported.\"\n",
    "        )\n",
    "\n",
    "    bins = expected_bins_0_to_100(step=5)\n",
    "\n",
    "    # Normalize STEEP_BIN labels\n",
    "    sbin = df[\"STEEP_BIN\"].apply(normalize_steep_bin_label)\n",
    "    valid = sbin.ne(\"\")\n",
    "\n",
    "    # ---- totals (denominators) ----\n",
    "    total_all = int(valid.sum())\n",
    "    total_res = int((valid & (df[ZONE_COL] == \"Residential Zone\")).sum())\n",
    "    total_nonres = int((valid & (df[ZONE_COL] == \"Non Residential Zone\")).sum())\n",
    "\n",
    "    out_rows = []\n",
    "    for b in bins:\n",
    "        all_cnt = int((valid & (sbin == b)).sum())\n",
    "        res_cnt = int(\n",
    "            (valid & (sbin == b) & (df[ZONE_COL] == \"Residential Zone\")).sum()\n",
    "        )\n",
    "        nonres_cnt = int(\n",
    "            (valid & (sbin == b) & (df[ZONE_COL] == \"Non Residential Zone\")).sum()\n",
    "        )\n",
    "\n",
    "        out_rows.append(\n",
    "            {\n",
    "                \"STEEP_BIN\": b,\n",
    "                \"All_parcels\": all_cnt,\n",
    "                \"All_%\": (all_cnt / total_all * 100.0) if total_all > 0 else 0.0,\n",
    "                \"Residential_Zone\": res_cnt,\n",
    "                \"Res_%\": (res_cnt / total_res * 100.0) if total_res > 0 else 0.0,\n",
    "                \"Non_Residential_Zone\": nonres_cnt,\n",
    "                \"Non-Res_%\": (\n",
    "                    nonres_cnt / total_nonres * 100.0 if total_nonres > 0 else 0.0\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    out_df = pd.DataFrame(out_rows)\n",
    "\n",
    "    # Optional: round percentage columns (consistent with rest of pipeline)\n",
    "    out_df = round_pct(out_df, [\"All_%\", \"Res_%\", \"Non-Res_%\"])\n",
    "\n",
    "    return out_df\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Main\n",
    "# --------------------------------------------------\n",
    "\n",
    "\n",
    "def run_analysis():\n",
    "    \"\"\"\n",
    "    operate post-processing analysis and export derived CSV tables.\n",
    "\n",
    "    Workflow\n",
    "    --------\n",
    "    1. Load and validate parcel-level delivery CSV\n",
    "    2. Export city-level slope summary table\n",
    "    3. Export zone-level slope exposure tables (including res vs non-res)\n",
    "    4. Export parcel-level steep exposure table\n",
    "    5. Export STEEP_BIN distribution counts (overall + res/non-res)\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - No plotting or spatial operations are performed in this function.\n",
    "    \"\"\"\n",
    "\n",
    "    df = load_parcel_slope_data()\n",
    "    print(\"Loaded parcels:\", df.shape)\n",
    "\n",
    "    # City-level summary\n",
    "    city = city_level_slope_stats(df)\n",
    "    city = round_pct(city, [\"area_pct\"])\n",
    "    city.to_csv(os.path.join(OUT_DIR, \"city_slope_stats.csv\"))\n",
    "    print(\"Saved city_slope_stats.csv\")\n",
    "\n",
    "    # Zone-level summary\n",
    "    zone = zone_level_slope_stats(df)\n",
    "    zone = round_pct(zone, [\"PCT_18PLUS\", \"PCT_25PLUS\", \"PCT_35PLUS\"])\n",
    "    zone.to_csv(os.path.join(OUT_DIR, \"zone_slope_stats.csv\"))\n",
    "    print(\"Saved zone_slope_stats.csv\")\n",
    "\n",
    "    # Residential vs Non-Residential comparison\n",
    "    res_nonres = export_res_vs_nonres(zone)\n",
    "    res_nonres = round_pct(res_nonres, [\"PCT_18PLUS\", \"PCT_25PLUS\", \"PCT_35PLUS\"])\n",
    "    res_nonres.to_csv(os.path.join(OUT_DIR, \"zone_slope_stats_res_vs_nonres.csv\"))\n",
    "    print(\"Saved zone_slope_stats_res_vs_nonres.csv\")\n",
    "\n",
    "    # Parcel-level steep stats\n",
    "    steep = parcel_level_steep_stats(df)\n",
    "    steep = round_pct(steep, [\"STEEP_AREA_PCT\"])\n",
    "    steep.to_csv(os.path.join(OUT_DIR, \"parcel_steep_stats.csv\"), index=False)\n",
    "    print(\"Saved parcel_steep_stats.csv\")\n",
    "\n",
    "    # STEEP_BIN counts for 0-5% ... 95-100% (overall + res/nonres)\n",
    "    steep_bin_counts = steep_bin_counts_overall_res_nonres(df)\n",
    "    steep_bin_counts.to_csv(\n",
    "        os.path.join(OUT_DIR, \"parcel_steep_bin_counts_0_100_res_nonres.csv\"),\n",
    "        index=False,\n",
    "    )\n",
    "    print(\"Saved parcel_steep_bin_counts_0_100_res_nonres.csv\")\n",
    "\n",
    "\n",
    "# Entry point: run post-processing analysis\n",
    "run_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All plots generated.\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================\n",
    "# Plot generation for Hamilton parcel-level slope analysis (attribute-only)\n",
    "# ==================================================================\n",
    "# This script reads analysis-ready CSV tables produced by the post-processing\n",
    "# statistics stage and generates publication-ready figures for reporting.\n",
    "#\n",
    "# Inputs (from data/output/csv)\n",
    "# -----------------------------\n",
    "# - zone_slope_stats.csv\n",
    "# - city_slope_stats.csv (optional)\n",
    "# - parcel_steep_bin_counts_0_100_res_nonres.csv\n",
    "#\n",
    "# Outputs (to data/output/plots)\n",
    "# -----------------------------\n",
    "# - Zone slope composition pie charts\n",
    "# - Zone steep exposure comparison charts (bar + stacked bar)\n",
    "# - Parcel steep-bin distribution charts (pie + res vs non-res bar)\n",
    "#\n",
    "# Notes\n",
    "# -----\n",
    "# - No ArcPy or spatial processing is performed here.\n",
    "# - All operations are pandas + matplotlib only.\n",
    "# - Figures are written to OUT_DIR.\n",
    "# ==================================================================\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Paths\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Directory containing analysis-ready CSV tables generated by the statistics script.\n",
    "CSV_DIR = os.path.join(PROJECT_ROOT, r\"data\\output\\csv\")\n",
    "\n",
    "# Output directory for all figure files generated by this script.\n",
    "OUT_DIR = os.path.join(PROJECT_ROOT, r\"data\\output\\plots\")\n",
    "\n",
    "# Ensure output directory exists so that fig.savefig() will not fail.\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Constants\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Zone-level summary table produced by zone_level_slope_stats()\n",
    "# Contains per-zone slope bin areas and derived steep indicators.\n",
    "ZONE_STATS_CSV = os.path.join(CSV_DIR, \"zone_slope_stats.csv\")\n",
    "\n",
    "# Parcel steep-bin distribution table produced by steep_bin_counts_overall_res_nonres()\n",
    "# Contains parcel counts by steep-slope proportion bins for overall/res/non-res.\n",
    "STEEP_BIN_COUNTS_CSV = os.path.join(\n",
    "    CSV_DIR, \"parcel_steep_bin_counts_0_100_res_nonres.csv\"\n",
    ")\n",
    "\n",
    "# Canonical zone labels used across the analysis pipeline.\n",
    "RES_ZONE = \"Residential Zone\"\n",
    "NONRES_ZONE = \"Non Residential Zone\"\n",
    "\n",
    "# Slope bin area fields used in zone_slope_stats.csv (degrees).\n",
    "# NOTE: These labels must match the Zone values in zone_slope_stats.csv.\n",
    "SLOPE_BINS = [\n",
    "    \"AREA_SLOPE_0_6\",\n",
    "    \"AREA_SLOPE_6_12\",\n",
    "    \"AREA_SLOPE_12_18\",\n",
    "    \"AREA_SLOPE_18_25\",\n",
    "    \"AREA_SLOPE_25_35\",\n",
    "    \"AREA_SLOPE_35_90\",\n",
    "]\n",
    "\n",
    "# Subset of bins defined as \"steep\" for zone-level comparisons (>=18 degrees).\n",
    "STEEP_BINS = [\n",
    "    \"AREA_SLOPE_18_25\",\n",
    "    \"AREA_SLOPE_25_35\",\n",
    "    \"AREA_SLOPE_35_90\",\n",
    "]\n",
    "\n",
    "# Columns expected in the parcel_steep_bin_counts_0_100_res_nonres.csv table.\n",
    "# These are counts (not percentages).\n",
    "STEEP_COUNT_COLS = [\"All_parcels\", \"Residential_Zone\", \"Non_Residential_Zone\"]\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Helper\n",
    "# --------------------------------------------------\n",
    "\n",
    "\n",
    "def pretty_bin(label: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert a slope-area field name into a human-readable bin label.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    'AREA_SLOPE_0_6' -> '0-6°'\n",
    "    \"\"\"\n",
    "\n",
    "    return label.replace(\"AREA_SLOPE_\", \"\").replace(\"_\", \"-\") + \"°\"\n",
    "\n",
    "\n",
    "def load_zone_stats() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and validate the zone-level slope statistics table.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    zone_slope_stats.csv (ZONE_STATS_CSV)\n",
    "\n",
    "    Validation\n",
    "    ----------\n",
    "    - Requires a 'Zone' column (used as index)\n",
    "    - Requires all SLOPE_BINS columns\n",
    "    - Requires TOTAL_AREA_M2 (for percentage-based plots)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame indexed by Zone.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(ZONE_STATS_CSV)\n",
    "\n",
    "    if \"Zone\" not in df.columns:\n",
    "        raise ValueError(\"zone_slope_stats.csv must contain a 'Zone' column.\")\n",
    "\n",
    "    df = df.set_index(\"Zone\")\n",
    "\n",
    "    missing_bins = [c for c in SLOPE_BINS if c not in df.columns]\n",
    "    if missing_bins:\n",
    "        raise ValueError(\n",
    "            f\"zone_slope_stats.csv missing slope bin columns: {missing_bins}\"\n",
    "        )\n",
    "\n",
    "    if \"TOTAL_AREA_M2\" not in df.columns:\n",
    "        raise ValueError(\"zone_slope_stats.csv must contain 'TOTAL_AREA_M2'.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def require_zones(df: pd.DataFrame, zones: list[str]) -> None:\n",
    "    \"\"\"\n",
    "    Validate that expected zone labels are present in the zone stats index.\n",
    "    \"\"\"\n",
    "\n",
    "    missing = [z for z in zones if z not in df.index]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing expected zones in zone stats: {missing}\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Steep-bin counts loaders / plots\n",
    "# --------------------------------------------------\n",
    "\n",
    "\n",
    "def load_steep_bin_counts() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and validate the parcel STEEP_BIN distribution counts table.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    parcel_steep_bin_counts_0_100_res_nonres.csv (STEEP_BIN_COUNTS_CSV)\n",
    "\n",
    "    Validation\n",
    "    ----------\n",
    "    - Requires STEEP_BIN column\n",
    "    - Requires expected count columns defined in STEEP_COUNT_COLS\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame in the bin order provided by the CSV (typically 0-5% ... 95-100%).\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(STEEP_BIN_COUNTS_CSV)\n",
    "\n",
    "    if \"STEEP_BIN\" not in df.columns:\n",
    "        raise ValueError(\"Steep-bin counts CSV must contain 'STEEP_BIN' column.\")\n",
    "\n",
    "    missing = [c for c in STEEP_COUNT_COLS if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Steep-bin counts CSV missing expected columns: {missing}\")\n",
    "\n",
    "    # Keep order as provided in the CSV (typically 0-5% ... 95-100%)\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_steep_bin_pie(column: str, out_name: str) -> None:\n",
    "    \"\"\"\n",
    "    Plot a STEEP_BIN distribution pie chart for a specified group.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    column : str\n",
    "        Count column to plot (e.g., 'All_parcels', 'Residential_Zone', 'Non_Residential_Zone').\n",
    "    out_name : str\n",
    "        Output filename under OUT_DIR.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    Saved figure file in OUT_DIR.\n",
    "    \"\"\"\n",
    "\n",
    "    df = load_steep_bin_counts()\n",
    "\n",
    "    if column not in df.columns:\n",
    "        raise ValueError(f\"Column '{column}' not found in steep-bin counts CSV.\")\n",
    "\n",
    "    labels = df[\"STEEP_BIN\"].astype(str).tolist()\n",
    "    values = pd.to_numeric(df[column], errors=\"coerce\").fillna(0).astype(int).tolist()\n",
    "\n",
    "    total = sum(values)\n",
    "    if total == 0:\n",
    "        raise ValueError(f\"Total count is 0 for column '{column}'. Nothing to plot.\")\n",
    "\n",
    "    # Legend text: bin + count + percentage\n",
    "    legend_labels = []\n",
    "    for lab, v in zip(labels, values):\n",
    "        pct = (v / total) * 100.0\n",
    "        legend_labels.append(f\"{lab}: {v} ({pct:.1f}%)\")\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    wedges, _ = ax.pie(values, labels=None, startangle=90)\n",
    "\n",
    "    ax.legend(\n",
    "        wedges,\n",
    "        legend_labels,\n",
    "        title=\"STEEP_BIN (count, %)\",\n",
    "        loc=\"center left\",\n",
    "        bbox_to_anchor=(1.0, 0.5),\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"Parcel distribution by STEEP_BIN ({column})\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(OUT_DIR, out_name), dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_res_vs_nonres_steep_bin_bar(out_name: str) -> None:\n",
    "    \"\"\"\n",
    "    Plot a side-by-side bar chart comparing Residential vs Non-Residential parcel\n",
    "    counts across STEEP_BIN categories.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    Saved figure file in OUT_DIR.\n",
    "    \"\"\"\n",
    "\n",
    "    df = load_steep_bin_counts()\n",
    "\n",
    "    bins = df[\"STEEP_BIN\"].astype(str).tolist()\n",
    "    res = (\n",
    "        pd.to_numeric(df[\"Residential_Zone\"], errors=\"coerce\")\n",
    "        .fillna(0)\n",
    "        .astype(int)\n",
    "        .tolist()\n",
    "    )\n",
    "    nonres = (\n",
    "        pd.to_numeric(df[\"Non_Residential_Zone\"], errors=\"coerce\")\n",
    "        .fillna(0)\n",
    "        .astype(int)\n",
    "        .tolist()\n",
    "    )\n",
    "\n",
    "    x = list(range(len(bins)))\n",
    "    width = 0.42\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    bars_res = plt.bar(\n",
    "        [i - width / 2 for i in x],\n",
    "        res,\n",
    "        width=width,\n",
    "        label=\"Residential Zone\",\n",
    "    )\n",
    "    bars_nonres = plt.bar(\n",
    "        [i + width / 2 for i in x],\n",
    "        nonres,\n",
    "        width=width,\n",
    "        label=\"Non-Residential Zone\",\n",
    "    )\n",
    "\n",
    "    # ---- add value labels ----\n",
    "    for bar in bars_res:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            plt.text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                height,\n",
    "                f\"{int(height)}\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontsize=8,\n",
    "            )\n",
    "\n",
    "    for bar in bars_nonres:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            plt.text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                height,\n",
    "                f\"{int(height)}\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontsize=8,\n",
    "            )\n",
    "\n",
    "    plt.xticks(x, bins, rotation=45, ha=\"right\")\n",
    "    plt.ylabel(\"Parcel count\")\n",
    "    plt.title(\"Residential vs Non-Residential parcel counts by steep slope proportion\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, out_name), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_city_slope():\n",
    "    \"\"\"\n",
    "    Plot city-level slope composition (area %), if city_slope_stats.csv is available.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    city_slope_stats.csv (generated by city_level_slope_stats())\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    fig_city_slope_distribution.png saved to OUT_DIR.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(os.path.join(CSV_DIR, \"city_slope_stats.csv\"))\n",
    "\n",
    "    # city_slope_stats.csv stores slope bin labels in the first column (often 'Unnamed: 0' after to_csv()).\n",
    "    labels = [pretty_bin(c) for c in df[\"Unnamed: 0\"]]\n",
    "    values = df[\"area_pct\"]\n",
    "\n",
    "    plt.figure()\n",
    "    bars = plt.bar(labels, values)\n",
    "\n",
    "    # Annotate each bar with its percentage value\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            height,\n",
    "            f\"{height:.1f}%\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=9,\n",
    "        )\n",
    "\n",
    "    plt.title(\"City-level slope distribution (area %)\")\n",
    "    plt.xlabel(\"Slope bin (degrees)\")\n",
    "    plt.ylabel(\"Percentage of total area (%)\")\n",
    "    plt.xticks(rotation=30, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, \"fig_city_slope_distribution.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_zone_slope_pie(zone_name: str):\n",
    "    \"\"\"\n",
    "    Plot slope composition (area %) as a pie chart for a single zone.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    zone_slope_stats.csv\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    Figure saved to OUT_DIR with a zone-specific filename.\n",
    "    \"\"\"\n",
    "\n",
    "    df = load_zone_stats()\n",
    "    require_zones(df, [zone_name])\n",
    "\n",
    "    row = df.loc[zone_name, SLOPE_BINS]\n",
    "    total = float(df.loc[zone_name, \"TOTAL_AREA_M2\"])\n",
    "\n",
    "    # Convert to percentages of the zone total area\n",
    "    pct = (row / total) * 100.0\n",
    "    values = pct.values\n",
    "\n",
    "    # Legend text: category + percentage\n",
    "    legend_labels = [\n",
    "        f\"{pretty_bin(bin_name)} ({pct_value:.1f}%)\"\n",
    "        for bin_name, pct_value in zip(SLOPE_BINS, values)\n",
    "    ]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    wedges, _ = ax.pie(\n",
    "        values,\n",
    "        labels=None,\n",
    "        startangle=90,\n",
    "    )\n",
    "\n",
    "    ax.legend(\n",
    "        wedges,\n",
    "        legend_labels,\n",
    "        title=\"Slope bin\",\n",
    "        loc=\"center left\",\n",
    "        bbox_to_anchor=(1.0, 0.5),\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"Slope composition within '{zone_name}'\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    out_name = (\n",
    "        \"fig_residential_slope_pie.png\"\n",
    "        if zone_name == RES_ZONE\n",
    "        else \"fig_nonresidential_slope_pie.png\"\n",
    "    )\n",
    "    fig.savefig(os.path.join(OUT_DIR, out_name), dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_steep_total_comparison():\n",
    "    \"\"\"\n",
    "    Plot total steep slope exposure (>=18°) comparison between Residential and Non-Residential zones.\n",
    "\n",
    "    Metric\n",
    "    ------\n",
    "    Percentage of total zone area classified as steep (>=18°).\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    fig_steep_total_comparison.png saved to OUT_DIR.\n",
    "    \"\"\"\n",
    "\n",
    "    df = load_zone_stats()\n",
    "    require_zones(df, [RES_ZONE, NONRES_ZONE])\n",
    "\n",
    "    # Prefer PCT_18PLUS if present; otherwise compute from area fields\n",
    "    if \"PCT_18PLUS\" in df.columns:\n",
    "        res = float(df.loc[RES_ZONE, \"PCT_18PLUS\"])\n",
    "        nonres = float(df.loc[NONRES_ZONE, \"PCT_18PLUS\"])\n",
    "    elif \"AREA_18PLUS_M2\" in df.columns:\n",
    "        res = float(\n",
    "            df.loc[RES_ZONE, \"AREA_18PLUS_M2\"]\n",
    "            / df.loc[RES_ZONE, \"TOTAL_AREA_M2\"]\n",
    "            * 100.0\n",
    "        )\n",
    "        nonres = float(\n",
    "            df.loc[NONRES_ZONE, \"AREA_18PLUS_M2\"]\n",
    "            / df.loc[NONRES_ZONE, \"TOTAL_AREA_M2\"]\n",
    "            * 100.0\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"zone_slope_stats.csv must contain PCT_18PLUS or AREA_18PLUS_M2.\"\n",
    "        )\n",
    "\n",
    "    zones = [RES_ZONE, NONRES_ZONE]\n",
    "    values = [res, nonres]\n",
    "\n",
    "    plt.figure()\n",
    "    bars = plt.bar(zones, values)\n",
    "\n",
    "    # Annotate\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            height,\n",
    "            f\"{height:.1f}%\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=9,\n",
    "        )\n",
    "\n",
    "    plt.ylabel(\"Percentage of zone area (%)\")\n",
    "    plt.title(\"Total steep slope exposure by zone (≥18°)\")\n",
    "    plt.xticks(rotation=15, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, \"fig_steep_total_comparison.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_steep_composition_comparison():\n",
    "    \"\"\"\n",
    "    Plot steep slope composition by zone as stacked bars (>=18° bins).\n",
    "\n",
    "    Interpretation\n",
    "    --------------\n",
    "    Bars show each steep bin (18-25, 25-35, 35-90) as a percentage of TOTAL zone area.\n",
    "    Values are not renormalised to sum to 100% of steep-only area.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    fig_steep_composition_comparison.png saved to OUT_DIR.\n",
    "    \"\"\"\n",
    "\n",
    "    df = load_zone_stats()\n",
    "    require_zones(df, [RES_ZONE, NONRES_ZONE])\n",
    "\n",
    "    zones = [RES_ZONE, NONRES_ZONE]\n",
    "    sub = df.loc[zones, STEEP_BINS]\n",
    "\n",
    "    # Percent of TOTAL zone area\n",
    "    pct = sub.div(df.loc[zones, \"TOTAL_AREA_M2\"], axis=0) * 100.0\n",
    "\n",
    "    x = range(len(zones))\n",
    "    bottom = None\n",
    "\n",
    "    plt.figure()\n",
    "    for col in STEEP_BINS:\n",
    "        vals = pct[col]\n",
    "        label = pretty_bin(col)\n",
    "        if bottom is None:\n",
    "            plt.bar(x, vals, label=label)\n",
    "            bottom = vals.copy()\n",
    "        else:\n",
    "            plt.bar(x, vals, bottom=bottom, label=label)\n",
    "            bottom += vals\n",
    "\n",
    "    # Annotate total steep percentage per zone\n",
    "    total_vals = pct.sum(axis=1)\n",
    "    for i, zone in enumerate(zones):\n",
    "        total = total_vals.loc[zone]\n",
    "        plt.text(\n",
    "            i,\n",
    "            total,\n",
    "            f\"{total:.1f}%\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=9,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "    plt.xticks(x, zones, rotation=15, ha=\"right\")\n",
    "    plt.ylabel(\"Percentage of zone area (%)\")\n",
    "    plt.title(\"Steep slope composition by zone (≥18° bins)\")\n",
    "    plt.legend(title=\"Slope bin\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(os.path.join(OUT_DIR, \"fig_steep_composition_comparison.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Main\n",
    "# --------------------------------------------------\n",
    "\n",
    "\n",
    "def generate_plots():\n",
    "    \"\"\"\n",
    "    Main entry point for figure generation.\n",
    "\n",
    "    Preconditions\n",
    "    -------------\n",
    "    The following CSV inputs must already exist in CSV_DIR:\n",
    "    - city_slope_stats.csv (optional)\n",
    "    - zone_slope_stats.csv\n",
    "    - parcel_steep_bin_counts_0_100_res_nonres.csv\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    All figures are saved to OUT_DIR.\n",
    "    \"\"\"\n",
    "\n",
    "    plot_city_slope()\n",
    "    plot_zone_slope_pie(RES_ZONE)\n",
    "    plot_zone_slope_pie(NONRES_ZONE)\n",
    "    plot_steep_total_comparison()\n",
    "    plot_steep_composition_comparison()\n",
    "\n",
    "    # Pie charts for All_parcels / Residential_Zone / Non_Residential_Zone\n",
    "    plot_steep_bin_pie(\"All_parcels\", \"fig_steep_bin_pie_all_parcels.png\")\n",
    "    plot_steep_bin_pie(\"Residential_Zone\", \"fig_steep_bin_pie_residential.png\")\n",
    "    plot_steep_bin_pie(\"Non_Residential_Zone\", \"fig_steep_bin_pie_non_residential.png\")\n",
    "\n",
    "    # Bar chart comparing Residential vs Non-Residential counts by STEEP_BIN\n",
    "    plot_res_vs_nonres_steep_bin_bar(\"fig_steep_bin_counts_res_vs_nonres.png\")\n",
    "\n",
    "    print(\"All plots generated.\")\n",
    "\n",
    "\n",
    "# Entry point: generate all plots\n",
    "generate_plots()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
